{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# HSE 2021: Mathematical Methods for Data Analysis\n",
    "\n",
    "## Homework 4\n",
    "\n",
    "**Warning 1**: You have 2 weeks for this assignemnt.  **it is better to start early (!)**\n",
    "\n",
    "**Warning 2**: it is critical to describe and explain what you are doing and why, use markdown cells\n",
    "\n",
    "\n",
    "### Contents\n",
    "\n",
    "#### Decision Trees - 7 points\n",
    "* [Task 1](#task1) (0.5 points)\n",
    "* [Task 2](#task2) (0.5 points)\n",
    "* [Task 3](#task3) (2 points)\n",
    "* [Task 4](#task4) (0.5 points)\n",
    "* [Task 5](#task5) (0.5 points)\n",
    "* [Task 6](#task6) (2 points)\n",
    "* [Task 7](#task7) (0.5 points)\n",
    "* [Task 8](#task8) (0.5 points)\n",
    "\n",
    "#### Ensembles - 3 points\n",
    "* [Task 1](#task2_1) (1 point)\n",
    "* [Task 2](#task2_2) (0.7 points)\n",
    "* [Task 3](#task2_3) (0.5 points)\n",
    "* [Task 4](#task2_4) (0.7 points)\n",
    "* [Task 5](#task2_5) (0.1 points)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (11, 5)\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 1. Decision Tree Regressor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this task you will be implementing decision tree for the regression by hand."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 1 <a id=\"task1\"></a> (0.5 points)\n",
    "\n",
    "Here you should implement the function `H()` which calculates impurity criterion. We will be training regression tree, and will take mean absolute deviation as impurity criterion.\n",
    "\n",
    "* You cannot use loops\n",
    "* If `y` is empty, the function should return 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "def H(y):\n",
    "    \"\"\"\n",
    "    Calculate impurity criterion\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : np.array\n",
    "        array of objects target values in the node\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    H(R) : float\n",
    "        Impurity in the node (measuread by variance)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    if len(y) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.sum(np.power((y - np.mean(y)), 2)) / len(y) #variance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "# Test the function\n",
    "assert np.allclose(H(np.array([4, 2, 2, 2])), 0.75)\n",
    "assert np.allclose(H(np.array([])), 0.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 2 <a id=\"task2\"></a>  (0.5 points)\n",
    "\n",
    "To find the best split in the node we need to calculate the cost function. Denote:\n",
    "- `R` all the object in the node\n",
    "- `j` index of the feature selected for the split\n",
    "- `t` threshold\n",
    "- `R_l` and `R_r` objects in the left and right child nodes correspondingly\n",
    "\n",
    "We get the following cost function:\n",
    "\n",
    "$$\n",
    "Q(R, j, t) =\\frac{|R_\\ell|}{|R|}H(R_\\ell) + \\frac{|R_r|}{|R|}H(R_r) \\to \\min_{j, t},\n",
    "$$\n",
    "\n",
    "Implement the function `Q`, which should calculate value of the cost function for a given feature and threshold."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "def Q(X, y, j, t):\n",
    "    \"\"\"\n",
    "    Calculate cost function\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray\n",
    "        array of objects in the node\n",
    "    y : ndarray\n",
    "        array of target values in the node\n",
    "    j : int\n",
    "        feature index (column in X)\n",
    "    t : float\n",
    "        threshold\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Q : float\n",
    "        Value of the cost function\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    x_col = X[:, j]\n",
    "\n",
    "    R_l = y[x_col <= t]\n",
    "    R_r = y[x_col > t]\n",
    "    tmp_r = H(R_r) / len(y)\n",
    "    tmp_l = H(R_l) / len(y)\n",
    "    Q = 0\n",
    "    return len(R_l) * tmp_l + len(R_r) * tmp_r\n",
    "    # return Q"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 3 <a id=\"task3\"></a>  (2 points)\n",
    "\n",
    "Now, let's implement `MyDecisionTreeRegressor` class. More specifically, you need to implement the following methods:\n",
    "\n",
    "- `best_split`\n",
    "- `grow_tree`\n",
    "- `get_prediction`\n",
    "\n",
    "Also, please add `min_samples_leaf` parameter to your class\n",
    "\n",
    "Read docstrings for more details. Do not forget to use function `Q` implemented above, when finding the `best_split`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \"\"\"\n",
    "    Class for a decision tree node.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    right : Node() or None\n",
    "        Right child\n",
    "    right : Node() or None\n",
    "        Left child\n",
    "    threshold: float\n",
    "\n",
    "    column: int\n",
    "\n",
    "    depth: int\n",
    "\n",
    "    prediction: float\n",
    "        prediction of the target value in the node\n",
    "        (average values calculated on a train dataset)\n",
    "    is_terminal:bool\n",
    "        indicates whether it is a terminal node (leaf) or not\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.right = None\n",
    "        self.left = None\n",
    "        self.threshold = None\n",
    "        self.column = None\n",
    "        self.depth = None\n",
    "        self.is_terminal = False\n",
    "        self.prediction = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.is_terminal:\n",
    "            node_desc = 'Pred: {:.2f}'.format(self.prediction)\n",
    "        else:\n",
    "            node_desc = 'Col {}, t {:.2f}, Pred: {:.2f}'. \\\n",
    "            format(self.column, self.threshold, self.prediction)\n",
    "        return node_desc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "\n",
    "class MyDecisionTreeRegressor(RegressorMixin, BaseEstimator):\n",
    "    \"\"\"\n",
    "    Class for a Decision Tree Regressor.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    max_depth : int\n",
    "        Max depth of a decision tree.\n",
    "    min_samples_split : int\n",
    "        Minimal number of samples (objects) in a node to make a split.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_depth=3, min_samples_split=2, min_samples_leaf=1):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "\n",
    "    def best_split(self, X, y):\n",
    "        \"\"\"\n",
    "        Find the best split in terms of Q of data in a given decision tree node.\n",
    "        Try all features and thresholds.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_objects, n_features)\n",
    "            Objects in the parent node\n",
    "        y : ndarray, shape (n_objects, )\n",
    "            1D array with the object labels.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        best_split_column : int\n",
    "            Index of the best split column\n",
    "        best_threshold : float\n",
    "            The best split condition.\n",
    "        X_left : ndarray, shape (n_objects_l, n_features)\n",
    "            Objects in the left child\n",
    "        y_left : ndarray, shape (n_objects_l, )\n",
    "            Objects labels in the left child.\n",
    "        X_right : ndarray, shape (n_objects_r, n_features)\n",
    "            Objects in the right child\n",
    "        y_right : ndarray, shape (n_objects_r, )\n",
    "            Objects labels in the right child.\n",
    "        \"\"\"\n",
    "\n",
    "        # To store best split parameters\n",
    "        best_split_column = None\n",
    "        best_threshold = None\n",
    "        best_cost = H(y)\n",
    "        best_information_gain = -999\n",
    "\n",
    "        # Data impurity before the split\n",
    "        # impurity = 0.8 (example)\n",
    "\n",
    "        # For each column in X ...\n",
    "        for split_column in range(X.shape[1]):\n",
    "\n",
    "            # Select values of the column\n",
    "            x_col = X[:, split_column]\n",
    "            # x_col = [2.6, 1.3, 0.5, ...] (example)\n",
    "\n",
    "            # For each value in the column ...\n",
    "            for i_x in range(0, len(x_col)):\n",
    "\n",
    "                # Take the value as a threshold for a split\n",
    "                threshold = x_col[i_x]\n",
    "                # threshold = 1.3 (example)\n",
    "\n",
    "                # Make the split into right and left childs\n",
    "                information_gain = best_cost - Q(X, y, split_column, threshold)\n",
    "                # information_gain = 0.2 (example)\n",
    "\n",
    "                # Is this information_gain the best?\n",
    "                if information_gain > best_information_gain:\n",
    "                    best_split_column = split_column\n",
    "                    best_threshold = threshold\n",
    "                    best_information_gain = information_gain\n",
    "\n",
    "        # If no split available\n",
    "        if best_information_gain == -999:\n",
    "            return None, None, None, None, None, None\n",
    "\n",
    "        # Take the best split parameters and make this split\n",
    "        x_col = X[:, best_split_column]\n",
    "        X_left = X[x_col <= best_threshold, :]\n",
    "        y_left = y[x_col <= best_threshold]\n",
    "        X_right = X[x_col > best_threshold, :]\n",
    "        y_right = y[x_col > best_threshold]\n",
    "\n",
    "        return best_split_column, best_threshold, X_left, y_left, X_right, y_right\n",
    "\n",
    "    def is_terminal(self, node, y):\n",
    "        \"\"\"\n",
    "        Check terminality conditions based on `max_depth`,\n",
    "        `min_samples_split` parameters for a given node.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        node : Node,\n",
    "\n",
    "        y : ndarray, shape (n_objects, )\n",
    "            Object labels.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Is_termial : bool\n",
    "            If True, node is terminal\n",
    "        \"\"\"\n",
    "        if node.depth >= self.max_depth:\n",
    "            return True\n",
    "        if len(y) < self.min_samples_split:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def grow_tree(self, node, X, y):\n",
    "        \"\"\"\n",
    "        Reccurently grow the tree from the `node` using a `X` and `y` as a dataset:\n",
    "         - check terminality conditions\n",
    "         - find best split if node is not terminal\n",
    "         - add child nodes to the node\n",
    "         - call the function recursively for the added child nodes\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        node : Node() object\n",
    "            Current node of the decision tree.\n",
    "        X : ndarray, shape (n_objects, n_features)\n",
    "            Objects\n",
    "        y : ndarray, shape (n_objects)\n",
    "            Labels\n",
    "        \"\"\"\n",
    "\n",
    "        if self.is_terminal(node, y):\n",
    "            node.is_terminal =True\n",
    "            return\n",
    "\n",
    "        # Check termination conditions\n",
    "        if len(np.unique(y)) == 1:\n",
    "            node.is_terminal = True\n",
    "            return\n",
    "\n",
    "        # Make best split\n",
    "        split_column, threshold, X_left, y_left, X_right, y_right = self.best_split(X, y) # Make a split\n",
    "        # split_column = 2 (exmaple) column index of the split\n",
    "        # threshold = 2.74 (example) split_column > threshold\n",
    "\n",
    "        # Check additional termination conditions\n",
    "        if split_column is None:\n",
    "            node.is_terminal = True\n",
    "            return\n",
    "        if len(X_left) < self.min_samples_leaf or len(X_right) < self.min_samples_leaf:  # min_samples_leaf check\n",
    "            node.is_terminal = True\n",
    "            return\n",
    "\n",
    "\n",
    "        # Add split parameters into the current node\n",
    "        node.column = split_column\n",
    "        node.threshold = threshold\n",
    "\n",
    "        # Create a left child of the current node\n",
    "        node.left = Node()\n",
    "        node.left.depth = node.depth + 1\n",
    "        node.left.prediction = np.mean(y_left)\n",
    "\n",
    "        # Create a right child of the current node\n",
    "        node.right = Node()\n",
    "        node.right.depth = node.depth + 1\n",
    "        node.right.prediction = np.mean(y_right)\n",
    "\n",
    "        # Make splits for the left and right nodes\n",
    "        self.grow_tree(node.right, X_right, y_right)\n",
    "        self.grow_tree(node.left, X_left, y_left)\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the Decision Tree Regressor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "        y : ndarray, shape (n_samples,) or (n_samples, n_outputs)\n",
    "            The target values.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        X, y = check_X_y(X, y, accept_sparse=False)\n",
    "        self.is_fitted_ = True\n",
    "\n",
    "        # Initialize the tree (root node)\n",
    "        self.tree_ = Node()\n",
    "        self.tree_.depth = 0\n",
    "        self.tree_.prediction = np.mean(y)\n",
    "\n",
    "        # Grow the tree\n",
    "        self.grow_tree(self.tree_, X, y)\n",
    "        return self\n",
    "\n",
    "    def get_prediction(self, node, x):\n",
    "        \"\"\"\n",
    "        Get prediction for an object `x`\n",
    "            - Return prediction of the `node` if it is terminal\n",
    "            - Otherwise, recursively call the function to get\n",
    "            predictions of the proper child\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        node : Node() object\n",
    "            Current node of the decision tree.\n",
    "        x : ndarray, shape (n_features,)\n",
    "            Array of feature values of one object.\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : float\n",
    "            Prediction for an object x\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        if node.is_terminal:\n",
    "            return node.prediction\n",
    "        if x[node.column] > node.threshold:\n",
    "            y_pred = self.get_prediction(node.right, x)\n",
    "        else:\n",
    "            y_pred = self.get_prediction(node.left, x)\n",
    "        return y_pred\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Get prediction for each object in X\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "        Returns\n",
    "        -------\n",
    "        y : ndarray, shape (n_samples,)\n",
    "            Returns predictions.\n",
    "        \"\"\"\n",
    "        # Check input and that `fit` had been called\n",
    "        X = check_array(X, accept_sparse=False)\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "\n",
    "        # Get predictions\n",
    "        y_predicted = []\n",
    "        for x in X:\n",
    "            y_curr = self.get_prediction(self.tree_, x)\n",
    "            y_predicted.append(y_curr)\n",
    "        return np.array(y_predicted)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\estimator_checks.py:3608: FutureWarning: As of scikit-learn 0.23, estimators should expose a n_features_in_ attribute, unless the 'no_validation' tag is True. This attribute should be equal to the number of features passed to the fit method. An error will be raised from version 1.0 (renaming of 0.25) when calling check_estimator(). See SLEP010: https://scikit-learn-enhancement-proposals.readthedocs.io/en/latest/slep010/proposal.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\estimator_checks.py:3652: FutureWarning: As of scikit-learn 0.23, estimators should have a 'requires_y' tag set to the appropriate value. The default value of the tag is False. An error will be raised from version 1.0 when calling check_estimator() if the tag isn't properly set.\n",
      "  warnings.warn(warning_msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# check yourself\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "\n",
    "check_estimator(MyDecisionTreeRegressor())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 4 <a id=\"task4\"></a>  (0.5 points)\n",
    "\n",
    "Load boston dataset and split it on the train ($75\\%$) and test ($25\\%$). Fit Decision Tree of depth 1 and make the following plot:\n",
    "\n",
    "- Scatter plot of the traning points (selected for split feature on the x-axis, target variable on the y-axis)\n",
    "- Fitted model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "data = load_boston()\n",
    "features_train, features_test, target_train, target_test = train_test_split(data.data, data.target, test_size = 0.25, random_state = 12345)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "MyDecisionTreeRegressor(max_depth=1)"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tree = MyDecisionTreeRegressor(max_depth=1)\n",
    "model_tree.fit(features_train, target_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x504 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_tree_predicted = model_tree.predict(features_train)\n",
    "tmp_col = features_train[:, model_tree.tree_.column]\n",
    "\n",
    "plt.gcf().set_size_inches(10, 7);\n",
    "\n",
    "plt.scatter(features_train[tmp_col <= model_tree.tree_.threshold][:, model_tree.tree_.column], target_train[tmp_col <= model_tree.tree_.threshold], color='red')\n",
    "\n",
    "plt.scatter(features_train[tmp_col > model_tree.tree_.threshold][:, model_tree.tree_.column], target_train[tmp_col > model_tree.tree_.threshold], color='green')\n",
    "\n",
    "plt.scatter(features_train[tmp_col <= model_tree.tree_.threshold][:, model_tree.tree_.column], model_tree_predicted[tmp_col <= model_tree.tree_.threshold], color ='black')\n",
    "\n",
    "plt.scatter(features_train[tmp_col > model_tree.tree_.threshold][:, model_tree.tree_.column], model_tree_predicted[tmp_col > model_tree.tree_.threshold], color ='yellow')\n",
    "\n",
    "plt.axvline(model_tree.tree_.threshold, color = 'blue');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from sklearn import tree\n",
    "#plt.figure(figsize=(70, 70))\n",
    "#tree.plot_tree(model_tree)\n",
    "#plt.show()\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Plot the results\n",
    "plt.figure()\n",
    "plt.plot(features_train, model_tree_predicted,\"o\", color=\"cornflowerblue\", linewidth=2)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"target\")\n",
    "plt.title(\"Decision Tree Regression\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 5 <a id=\"task5\"></a>  (0.5 points)\n",
    "\n",
    "Keep working with boston dataset.\n",
    "- Use `GridSearchCV` to find the best hyperparameters among [`max_depth`, `min_samples_leaf`] on 5-Fold cross-validation\n",
    "- Train the model with the best set of hyperparameters on the whole train dataset.\n",
    "- Report `MAE` on test dataset and hyperparameters of the best estimator."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 1/5] END ..max_depth=0, min_samples_leaf=0;, score=-7.454 total time=   0.0s\n",
      "[CV 2/5] END ..max_depth=0, min_samples_leaf=0;, score=-6.898 total time=   0.0s\n",
      "[CV 3/5] END ..max_depth=0, min_samples_leaf=0;, score=-7.502 total time=   0.0s\n",
      "[CV 4/5] END ..max_depth=0, min_samples_leaf=0;, score=-5.827 total time=   0.0s\n",
      "[CV 5/5] END ..max_depth=0, min_samples_leaf=0;, score=-7.347 total time=   0.0s\n",
      "[CV 1/5] END ..max_depth=0, min_samples_leaf=1;, score=-7.454 total time=   0.0s\n",
      "[CV 2/5] END ..max_depth=0, min_samples_leaf=1;, score=-6.898 total time=   0.0s\n",
      "[CV 3/5] END ..max_depth=0, min_samples_leaf=1;, score=-7.502 total time=   0.0s\n",
      "[CV 4/5] END ..max_depth=0, min_samples_leaf=1;, score=-5.827 total time=   0.0s\n",
      "[CV 5/5] END ..max_depth=0, min_samples_leaf=1;, score=-7.347 total time=   0.0s\n",
      "[CV 1/5] END ..max_depth=0, min_samples_leaf=2;, score=-7.454 total time=   0.0s\n",
      "[CV 2/5] END ..max_depth=0, min_samples_leaf=2;, score=-6.898 total time=   0.0s\n",
      "[CV 3/5] END ..max_depth=0, min_samples_leaf=2;, score=-7.502 total time=   0.0s\n",
      "[CV 4/5] END ..max_depth=0, min_samples_leaf=2;, score=-5.827 total time=   0.0s\n",
      "[CV 5/5] END ..max_depth=0, min_samples_leaf=2;, score=-7.347 total time=   0.0s\n",
      "[CV 1/5] END ..max_depth=0, min_samples_leaf=3;, score=-7.454 total time=   0.0s\n",
      "[CV 2/5] END ..max_depth=0, min_samples_leaf=3;, score=-6.898 total time=   0.0s\n",
      "[CV 3/5] END ..max_depth=0, min_samples_leaf=3;, score=-7.502 total time=   0.0s\n",
      "[CV 4/5] END ..max_depth=0, min_samples_leaf=3;, score=-5.827 total time=   0.0s\n",
      "[CV 5/5] END ..max_depth=0, min_samples_leaf=3;, score=-7.347 total time=   0.0s\n",
      "[CV 1/5] END ..max_depth=0, min_samples_leaf=4;, score=-7.454 total time=   0.0s\n",
      "[CV 2/5] END ..max_depth=0, min_samples_leaf=4;, score=-6.898 total time=   0.0s\n",
      "[CV 3/5] END ..max_depth=0, min_samples_leaf=4;, score=-7.502 total time=   0.0s\n",
      "[CV 4/5] END ..max_depth=0, min_samples_leaf=4;, score=-5.827 total time=   0.0s\n",
      "[CV 5/5] END ..max_depth=0, min_samples_leaf=4;, score=-7.347 total time=   0.0s\n",
      "[CV 1/5] END ..max_depth=0, min_samples_leaf=5;, score=-7.454 total time=   0.0s\n",
      "[CV 2/5] END ..max_depth=0, min_samples_leaf=5;, score=-6.898 total time=   0.0s\n",
      "[CV 3/5] END ..max_depth=0, min_samples_leaf=5;, score=-7.502 total time=   0.0s\n",
      "[CV 4/5] END ..max_depth=0, min_samples_leaf=5;, score=-5.827 total time=   0.0s\n",
      "[CV 5/5] END ..max_depth=0, min_samples_leaf=5;, score=-7.347 total time=   0.0s\n",
      "[CV 1/5] END ..max_depth=0, min_samples_leaf=6;, score=-7.454 total time=   0.0s\n",
      "[CV 2/5] END ..max_depth=0, min_samples_leaf=6;, score=-6.898 total time=   0.0s\n",
      "[CV 3/5] END ..max_depth=0, min_samples_leaf=6;, score=-7.502 total time=   0.0s\n",
      "[CV 4/5] END ..max_depth=0, min_samples_leaf=6;, score=-5.827 total time=   0.0s\n",
      "[CV 5/5] END ..max_depth=0, min_samples_leaf=6;, score=-7.347 total time=   0.0s\n",
      "[CV 1/5] END ..max_depth=0, min_samples_leaf=7;, score=-7.454 total time=   0.0s\n",
      "[CV 2/5] END ..max_depth=0, min_samples_leaf=7;, score=-6.898 total time=   0.0s\n",
      "[CV 3/5] END ..max_depth=0, min_samples_leaf=7;, score=-7.502 total time=   0.0s\n",
      "[CV 4/5] END ..max_depth=0, min_samples_leaf=7;, score=-5.827 total time=   0.0s\n",
      "[CV 5/5] END ..max_depth=0, min_samples_leaf=7;, score=-7.347 total time=   0.0s\n",
      "[CV 1/5] END ..max_depth=0, min_samples_leaf=8;, score=-7.454 total time=   0.0s\n",
      "[CV 2/5] END ..max_depth=0, min_samples_leaf=8;, score=-6.898 total time=   0.0s\n",
      "[CV 3/5] END ..max_depth=0, min_samples_leaf=8;, score=-7.502 total time=   0.0s\n",
      "[CV 4/5] END ..max_depth=0, min_samples_leaf=8;, score=-5.827 total time=   0.0s\n",
      "[CV 5/5] END ..max_depth=0, min_samples_leaf=8;, score=-7.347 total time=   0.0s\n",
      "[CV 1/5] END ..max_depth=0, min_samples_leaf=9;, score=-7.454 total time=   0.0s\n",
      "[CV 2/5] END ..max_depth=0, min_samples_leaf=9;, score=-6.898 total time=   0.0s\n",
      "[CV 3/5] END ..max_depth=0, min_samples_leaf=9;, score=-7.502 total time=   0.0s\n",
      "[CV 4/5] END ..max_depth=0, min_samples_leaf=9;, score=-5.827 total time=   0.0s\n",
      "[CV 5/5] END ..max_depth=0, min_samples_leaf=9;, score=-7.347 total time=   0.0s\n",
      "[CV 1/5] END ..max_depth=1, min_samples_leaf=0;, score=-5.457 total time=   0.4s\n",
      "[CV 2/5] END ..max_depth=1, min_samples_leaf=0;, score=-5.343 total time=   0.3s\n",
      "[CV 3/5] END ..max_depth=1, min_samples_leaf=0;, score=-5.269 total time=   0.4s\n",
      "[CV 4/5] END ..max_depth=1, min_samples_leaf=0;, score=-5.043 total time=   0.4s\n",
      "[CV 5/5] END ..max_depth=1, min_samples_leaf=0;, score=-5.454 total time=   0.4s\n",
      "[CV 1/5] END ..max_depth=1, min_samples_leaf=1;, score=-5.457 total time=   0.5s\n",
      "[CV 2/5] END ..max_depth=1, min_samples_leaf=1;, score=-5.343 total time=   0.4s\n",
      "[CV 3/5] END ..max_depth=1, min_samples_leaf=1;, score=-5.269 total time=   0.4s\n",
      "[CV 4/5] END ..max_depth=1, min_samples_leaf=1;, score=-5.043 total time=   0.3s\n",
      "[CV 5/5] END ..max_depth=1, min_samples_leaf=1;, score=-5.454 total time=   0.3s\n",
      "[CV 1/5] END ..max_depth=1, min_samples_leaf=2;, score=-5.457 total time=   0.3s\n",
      "[CV 2/5] END ..max_depth=1, min_samples_leaf=2;, score=-5.343 total time=   0.4s\n",
      "[CV 3/5] END ..max_depth=1, min_samples_leaf=2;, score=-5.269 total time=   0.3s\n",
      "[CV 4/5] END ..max_depth=1, min_samples_leaf=2;, score=-5.043 total time=   0.3s\n",
      "[CV 5/5] END ..max_depth=1, min_samples_leaf=2;, score=-5.454 total time=   0.2s\n",
      "[CV 1/5] END ..max_depth=1, min_samples_leaf=3;, score=-5.457 total time=   0.3s\n",
      "[CV 2/5] END ..max_depth=1, min_samples_leaf=3;, score=-5.343 total time=   0.2s\n",
      "[CV 3/5] END ..max_depth=1, min_samples_leaf=3;, score=-5.269 total time=   0.2s\n",
      "[CV 4/5] END ..max_depth=1, min_samples_leaf=3;, score=-5.043 total time=   0.2s\n",
      "[CV 5/5] END ..max_depth=1, min_samples_leaf=3;, score=-5.454 total time=   0.2s\n",
      "[CV 1/5] END ..max_depth=1, min_samples_leaf=4;, score=-5.457 total time=   0.2s\n",
      "[CV 2/5] END ..max_depth=1, min_samples_leaf=4;, score=-5.343 total time=   0.3s\n",
      "[CV 3/5] END ..max_depth=1, min_samples_leaf=4;, score=-5.269 total time=   0.4s\n",
      "[CV 4/5] END ..max_depth=1, min_samples_leaf=4;, score=-5.043 total time=   0.4s\n",
      "[CV 5/5] END ..max_depth=1, min_samples_leaf=4;, score=-5.454 total time=   0.3s\n",
      "[CV 1/5] END ..max_depth=1, min_samples_leaf=5;, score=-5.457 total time=   0.3s\n",
      "[CV 2/5] END ..max_depth=1, min_samples_leaf=5;, score=-5.343 total time=   0.3s\n",
      "[CV 3/5] END ..max_depth=1, min_samples_leaf=5;, score=-5.269 total time=   0.5s\n",
      "[CV 4/5] END ..max_depth=1, min_samples_leaf=5;, score=-5.043 total time=   0.4s\n",
      "[CV 5/5] END ..max_depth=1, min_samples_leaf=5;, score=-5.454 total time=   0.4s\n",
      "[CV 1/5] END ..max_depth=1, min_samples_leaf=6;, score=-5.457 total time=   0.4s\n",
      "[CV 2/5] END ..max_depth=1, min_samples_leaf=6;, score=-5.343 total time=   0.4s\n",
      "[CV 3/5] END ..max_depth=1, min_samples_leaf=6;, score=-5.269 total time=   0.5s\n",
      "[CV 4/5] END ..max_depth=1, min_samples_leaf=6;, score=-5.043 total time=   0.3s\n",
      "[CV 5/5] END ..max_depth=1, min_samples_leaf=6;, score=-5.454 total time=   0.3s\n",
      "[CV 1/5] END ..max_depth=1, min_samples_leaf=7;, score=-5.457 total time=   0.3s\n",
      "[CV 2/5] END ..max_depth=1, min_samples_leaf=7;, score=-5.343 total time=   0.3s\n",
      "[CV 3/5] END ..max_depth=1, min_samples_leaf=7;, score=-5.269 total time=   0.3s\n",
      "[CV 4/5] END ..max_depth=1, min_samples_leaf=7;, score=-5.043 total time=   0.3s\n",
      "[CV 5/5] END ..max_depth=1, min_samples_leaf=7;, score=-5.454 total time=   0.3s\n",
      "[CV 1/5] END ..max_depth=1, min_samples_leaf=8;, score=-5.457 total time=   0.3s\n",
      "[CV 2/5] END ..max_depth=1, min_samples_leaf=8;, score=-5.343 total time=   0.3s\n",
      "[CV 3/5] END ..max_depth=1, min_samples_leaf=8;, score=-5.269 total time=   0.3s\n",
      "[CV 4/5] END ..max_depth=1, min_samples_leaf=8;, score=-5.043 total time=   0.3s\n",
      "[CV 5/5] END ..max_depth=1, min_samples_leaf=8;, score=-5.454 total time=   0.3s\n",
      "[CV 1/5] END ..max_depth=1, min_samples_leaf=9;, score=-5.457 total time=   0.2s\n",
      "[CV 2/5] END ..max_depth=1, min_samples_leaf=9;, score=-5.343 total time=   0.2s\n",
      "[CV 3/5] END ..max_depth=1, min_samples_leaf=9;, score=-5.269 total time=   0.2s\n",
      "[CV 4/5] END ..max_depth=1, min_samples_leaf=9;, score=-5.043 total time=   0.2s\n",
      "[CV 5/5] END ..max_depth=1, min_samples_leaf=9;, score=-5.454 total time=   0.2s\n",
      "[CV 1/5] END ..max_depth=2, min_samples_leaf=0;, score=-3.778 total time=   0.5s\n",
      "[CV 2/5] END ..max_depth=2, min_samples_leaf=0;, score=-3.561 total time=   0.5s\n",
      "[CV 3/5] END ..max_depth=2, min_samples_leaf=0;, score=-4.541 total time=   0.5s\n",
      "[CV 4/5] END ..max_depth=2, min_samples_leaf=0;, score=-3.376 total time=   0.5s\n",
      "[CV 5/5] END ..max_depth=2, min_samples_leaf=0;, score=-3.909 total time=   0.4s\n",
      "[CV 1/5] END ..max_depth=2, min_samples_leaf=1;, score=-3.778 total time=   0.4s\n",
      "[CV 2/5] END ..max_depth=2, min_samples_leaf=1;, score=-3.561 total time=   0.8s\n",
      "[CV 3/5] END ..max_depth=2, min_samples_leaf=1;, score=-4.541 total time=   0.6s\n",
      "[CV 4/5] END ..max_depth=2, min_samples_leaf=1;, score=-3.376 total time=   0.7s\n",
      "[CV 5/5] END ..max_depth=2, min_samples_leaf=1;, score=-3.909 total time=   0.8s\n",
      "[CV 1/5] END ..max_depth=2, min_samples_leaf=2;, score=-3.778 total time=   0.7s\n",
      "[CV 2/5] END ..max_depth=2, min_samples_leaf=2;, score=-3.561 total time=   0.7s\n",
      "[CV 3/5] END ..max_depth=2, min_samples_leaf=2;, score=-4.541 total time=   0.7s\n",
      "[CV 4/5] END ..max_depth=2, min_samples_leaf=2;, score=-3.376 total time=   0.7s\n",
      "[CV 5/5] END ..max_depth=2, min_samples_leaf=2;, score=-3.909 total time=   0.7s\n",
      "[CV 1/5] END ..max_depth=2, min_samples_leaf=3;, score=-3.778 total time=   0.8s\n",
      "[CV 2/5] END ..max_depth=2, min_samples_leaf=3;, score=-3.561 total time=   0.7s\n",
      "[CV 3/5] END ..max_depth=2, min_samples_leaf=3;, score=-4.541 total time=   0.7s\n",
      "[CV 4/5] END ..max_depth=2, min_samples_leaf=3;, score=-3.376 total time=   0.5s\n",
      "[CV 5/5] END ..max_depth=2, min_samples_leaf=3;, score=-3.909 total time=   0.5s\n",
      "[CV 1/5] END ..max_depth=2, min_samples_leaf=4;, score=-3.778 total time=   0.5s\n",
      "[CV 2/5] END ..max_depth=2, min_samples_leaf=4;, score=-3.561 total time=   0.5s\n",
      "[CV 3/5] END ..max_depth=2, min_samples_leaf=4;, score=-4.541 total time=   0.5s\n",
      "[CV 4/5] END ..max_depth=2, min_samples_leaf=4;, score=-3.376 total time=   0.5s\n",
      "[CV 5/5] END ..max_depth=2, min_samples_leaf=4;, score=-3.909 total time=   0.5s\n",
      "[CV 1/5] END ..max_depth=2, min_samples_leaf=5;, score=-3.778 total time=   0.5s\n",
      "[CV 2/5] END ..max_depth=2, min_samples_leaf=5;, score=-3.561 total time=   0.5s\n",
      "[CV 3/5] END ..max_depth=2, min_samples_leaf=5;, score=-4.541 total time=   0.7s\n",
      "[CV 4/5] END ..max_depth=2, min_samples_leaf=5;, score=-3.376 total time=   0.7s\n",
      "[CV 5/5] END ..max_depth=2, min_samples_leaf=5;, score=-3.909 total time=   0.7s\n",
      "[CV 1/5] END ..max_depth=2, min_samples_leaf=6;, score=-3.778 total time=   0.8s\n",
      "[CV 2/5] END ..max_depth=2, min_samples_leaf=6;, score=-3.561 total time=   0.7s\n",
      "[CV 3/5] END ..max_depth=2, min_samples_leaf=6;, score=-4.541 total time=   0.7s\n",
      "[CV 4/5] END ..max_depth=2, min_samples_leaf=6;, score=-3.376 total time=   0.6s\n",
      "[CV 5/5] END ..max_depth=2, min_samples_leaf=6;, score=-3.909 total time=   0.6s\n",
      "[CV 1/5] END ..max_depth=2, min_samples_leaf=7;, score=-3.778 total time=   0.8s\n",
      "[CV 2/5] END ..max_depth=2, min_samples_leaf=7;, score=-3.561 total time=   0.8s\n",
      "[CV 3/5] END ..max_depth=2, min_samples_leaf=7;, score=-4.541 total time=   0.7s\n",
      "[CV 4/5] END ..max_depth=2, min_samples_leaf=7;, score=-3.376 total time=   0.7s\n",
      "[CV 5/5] END ..max_depth=2, min_samples_leaf=7;, score=-3.909 total time=   0.5s\n",
      "[CV 1/5] END ..max_depth=2, min_samples_leaf=8;, score=-3.778 total time=   0.5s\n",
      "[CV 2/5] END ..max_depth=2, min_samples_leaf=8;, score=-3.561 total time=   0.6s\n",
      "[CV 3/5] END ..max_depth=2, min_samples_leaf=8;, score=-4.541 total time=   0.5s\n",
      "[CV 4/5] END ..max_depth=2, min_samples_leaf=8;, score=-3.376 total time=   0.5s\n",
      "[CV 5/5] END ..max_depth=2, min_samples_leaf=8;, score=-3.909 total time=   0.5s\n",
      "[CV 1/5] END ..max_depth=2, min_samples_leaf=9;, score=-3.778 total time=   0.5s\n",
      "[CV 2/5] END ..max_depth=2, min_samples_leaf=9;, score=-3.561 total time=   0.5s\n",
      "[CV 3/5] END ..max_depth=2, min_samples_leaf=9;, score=-4.541 total time=   0.6s\n",
      "[CV 4/5] END ..max_depth=2, min_samples_leaf=9;, score=-3.376 total time=   0.7s\n",
      "[CV 5/5] END ..max_depth=2, min_samples_leaf=9;, score=-3.909 total time=   0.7s\n",
      "[CV 1/5] END ..max_depth=3, min_samples_leaf=0;, score=-3.670 total time=   1.1s\n",
      "[CV 2/5] END ..max_depth=3, min_samples_leaf=0;, score=-3.125 total time=   1.0s\n",
      "[CV 3/5] END ..max_depth=3, min_samples_leaf=0;, score=-4.179 total time=   1.1s\n",
      "[CV 4/5] END ..max_depth=3, min_samples_leaf=0;, score=-2.860 total time=   1.0s\n",
      "[CV 5/5] END ..max_depth=3, min_samples_leaf=0;, score=-3.991 total time=   1.1s\n",
      "[CV 1/5] END ..max_depth=3, min_samples_leaf=1;, score=-3.670 total time=   1.0s\n",
      "[CV 2/5] END ..max_depth=3, min_samples_leaf=1;, score=-3.125 total time=   0.9s\n",
      "[CV 3/5] END ..max_depth=3, min_samples_leaf=1;, score=-4.179 total time=   0.7s\n",
      "[CV 4/5] END ..max_depth=3, min_samples_leaf=1;, score=-2.860 total time=   0.7s\n",
      "[CV 5/5] END ..max_depth=3, min_samples_leaf=1;, score=-3.991 total time=   0.7s\n",
      "[CV 1/5] END ..max_depth=3, min_samples_leaf=2;, score=-3.670 total time=   0.7s\n",
      "[CV 2/5] END ..max_depth=3, min_samples_leaf=2;, score=-3.233 total time=   0.7s\n",
      "[CV 3/5] END ..max_depth=3, min_samples_leaf=2;, score=-4.179 total time=   0.7s\n",
      "[CV 4/5] END ..max_depth=3, min_samples_leaf=2;, score=-2.818 total time=   1.0s\n",
      "[CV 5/5] END ..max_depth=3, min_samples_leaf=2;, score=-3.706 total time=   1.0s\n",
      "[CV 1/5] END ..max_depth=3, min_samples_leaf=3;, score=-3.689 total time=   1.0s\n",
      "[CV 2/5] END ..max_depth=3, min_samples_leaf=3;, score=-3.233 total time=   1.1s\n",
      "[CV 3/5] END ..max_depth=3, min_samples_leaf=3;, score=-4.384 total time=   1.0s\n",
      "[CV 4/5] END ..max_depth=3, min_samples_leaf=3;, score=-3.049 total time=   1.0s\n",
      "[CV 5/5] END ..max_depth=3, min_samples_leaf=3;, score=-3.706 total time=   1.1s\n",
      "[CV 1/5] END ..max_depth=3, min_samples_leaf=4;, score=-3.689 total time=   1.0s\n",
      "[CV 2/5] END ..max_depth=3, min_samples_leaf=4;, score=-3.233 total time=   1.1s\n",
      "[CV 3/5] END ..max_depth=3, min_samples_leaf=4;, score=-4.627 total time=   0.8s\n",
      "[CV 4/5] END ..max_depth=3, min_samples_leaf=4;, score=-3.049 total time=   0.9s\n",
      "[CV 5/5] END ..max_depth=3, min_samples_leaf=4;, score=-3.677 total time=   0.7s\n",
      "[CV 1/5] END ..max_depth=3, min_samples_leaf=5;, score=-3.698 total time=   0.8s\n",
      "[CV 2/5] END ..max_depth=3, min_samples_leaf=5;, score=-3.328 total time=   1.0s\n",
      "[CV 3/5] END ..max_depth=3, min_samples_leaf=5;, score=-4.627 total time=   1.2s\n",
      "[CV 4/5] END ..max_depth=3, min_samples_leaf=5;, score=-3.020 total time=   1.2s\n",
      "[CV 5/5] END ..max_depth=3, min_samples_leaf=5;, score=-3.677 total time=   1.1s\n",
      "[CV 1/5] END ..max_depth=3, min_samples_leaf=6;, score=-3.698 total time=   1.1s\n",
      "[CV 2/5] END ..max_depth=3, min_samples_leaf=6;, score=-3.328 total time=   1.0s\n",
      "[CV 3/5] END ..max_depth=3, min_samples_leaf=6;, score=-4.627 total time=   1.1s\n",
      "[CV 4/5] END ..max_depth=3, min_samples_leaf=6;, score=-3.020 total time=   1.1s\n",
      "[CV 5/5] END ..max_depth=3, min_samples_leaf=6;, score=-3.677 total time=   1.0s\n",
      "[CV 1/5] END ..max_depth=3, min_samples_leaf=7;, score=-3.698 total time=   0.7s\n",
      "[CV 2/5] END ..max_depth=3, min_samples_leaf=7;, score=-3.328 total time=   0.7s\n",
      "[CV 3/5] END ..max_depth=3, min_samples_leaf=7;, score=-4.470 total time=   0.7s\n",
      "[CV 4/5] END ..max_depth=3, min_samples_leaf=7;, score=-3.020 total time=   0.7s\n",
      "[CV 5/5] END ..max_depth=3, min_samples_leaf=7;, score=-3.677 total time=   0.7s\n",
      "[CV 1/5] END ..max_depth=3, min_samples_leaf=8;, score=-3.698 total time=   0.7s\n",
      "[CV 2/5] END ..max_depth=3, min_samples_leaf=8;, score=-3.328 total time=   0.9s\n",
      "[CV 3/5] END ..max_depth=3, min_samples_leaf=8;, score=-4.470 total time=   1.0s\n",
      "[CV 4/5] END ..max_depth=3, min_samples_leaf=8;, score=-3.020 total time=   1.1s\n",
      "[CV 5/5] END ..max_depth=3, min_samples_leaf=8;, score=-3.677 total time=   1.0s\n",
      "[CV 1/5] END ..max_depth=3, min_samples_leaf=9;, score=-3.698 total time=   1.0s\n",
      "[CV 2/5] END ..max_depth=3, min_samples_leaf=9;, score=-3.328 total time=   0.9s\n",
      "[CV 3/5] END ..max_depth=3, min_samples_leaf=9;, score=-4.470 total time=   1.0s\n",
      "[CV 4/5] END ..max_depth=3, min_samples_leaf=9;, score=-3.020 total time=   1.1s\n",
      "[CV 5/5] END ..max_depth=3, min_samples_leaf=9;, score=-3.677 total time=   1.0s\n",
      "[CV 1/5] END ..max_depth=4, min_samples_leaf=0;, score=-3.103 total time=   0.9s\n",
      "[CV 2/5] END ..max_depth=4, min_samples_leaf=0;, score=-2.844 total time=   1.0s\n",
      "[CV 3/5] END ..max_depth=4, min_samples_leaf=0;, score=-3.787 total time=   1.2s\n",
      "[CV 4/5] END ..max_depth=4, min_samples_leaf=0;, score=-2.604 total time=   1.0s\n",
      "[CV 5/5] END ..max_depth=4, min_samples_leaf=0;, score=-3.877 total time=   1.6s\n",
      "[CV 1/5] END ..max_depth=4, min_samples_leaf=1;, score=-3.103 total time=   1.7s\n",
      "[CV 2/5] END ..max_depth=4, min_samples_leaf=1;, score=-2.844 total time=   1.8s\n",
      "[CV 3/5] END ..max_depth=4, min_samples_leaf=1;, score=-3.787 total time=   1.3s\n",
      "[CV 4/5] END ..max_depth=4, min_samples_leaf=1;, score=-2.604 total time=   1.4s\n",
      "[CV 5/5] END ..max_depth=4, min_samples_leaf=1;, score=-3.877 total time=   1.5s\n",
      "[CV 1/5] END ..max_depth=4, min_samples_leaf=2;, score=-3.058 total time=   1.3s\n",
      "[CV 2/5] END ..max_depth=4, min_samples_leaf=2;, score=-2.950 total time=   0.9s\n",
      "[CV 3/5] END ..max_depth=4, min_samples_leaf=2;, score=-3.755 total time=   0.9s\n",
      "[CV 4/5] END ..max_depth=4, min_samples_leaf=2;, score=-2.522 total time=   0.9s\n",
      "[CV 5/5] END ..max_depth=4, min_samples_leaf=2;, score=-3.584 total time=   0.8s\n",
      "[CV 1/5] END ..max_depth=4, min_samples_leaf=3;, score=-3.055 total time=   0.9s\n",
      "[CV 2/5] END ..max_depth=4, min_samples_leaf=3;, score=-2.950 total time=   1.3s\n",
      "[CV 3/5] END ..max_depth=4, min_samples_leaf=3;, score=-4.328 total time=   1.8s\n",
      "[CV 4/5] END ..max_depth=4, min_samples_leaf=3;, score=-2.736 total time=   1.8s\n",
      "[CV 5/5] END ..max_depth=4, min_samples_leaf=3;, score=-3.584 total time=   1.5s\n",
      "[CV 1/5] END ..max_depth=4, min_samples_leaf=4;, score=-3.055 total time=   1.7s\n",
      "[CV 2/5] END ..max_depth=4, min_samples_leaf=4;, score=-2.950 total time=   1.6s\n",
      "[CV 3/5] END ..max_depth=4, min_samples_leaf=4;, score=-4.621 total time=   1.2s\n",
      "[CV 4/5] END ..max_depth=4, min_samples_leaf=4;, score=-2.736 total time=   1.0s\n",
      "[CV 5/5] END ..max_depth=4, min_samples_leaf=4;, score=-3.481 total time=   0.8s\n",
      "[CV 1/5] END ..max_depth=4, min_samples_leaf=5;, score=-3.392 total time=   0.9s\n",
      "[CV 2/5] END ..max_depth=4, min_samples_leaf=5;, score=-3.188 total time=   1.0s\n",
      "[CV 3/5] END ..max_depth=4, min_samples_leaf=5;, score=-4.621 total time=   0.8s\n",
      "[CV 4/5] END ..max_depth=4, min_samples_leaf=5;, score=-2.652 total time=   2.9s\n",
      "[CV 5/5] END ..max_depth=4, min_samples_leaf=5;, score=-3.481 total time=   1.6s\n",
      "[CV 1/5] END ..max_depth=4, min_samples_leaf=6;, score=-3.392 total time=   1.2s\n",
      "[CV 2/5] END ..max_depth=4, min_samples_leaf=6;, score=-3.188 total time=   1.3s\n",
      "[CV 3/5] END ..max_depth=4, min_samples_leaf=6;, score=-4.621 total time=   1.2s\n",
      "[CV 4/5] END ..max_depth=4, min_samples_leaf=6;, score=-2.652 total time=   2.4s\n",
      "[CV 5/5] END ..max_depth=4, min_samples_leaf=6;, score=-3.483 total time=   2.0s\n",
      "[CV 1/5] END ..max_depth=4, min_samples_leaf=7;, score=-3.459 total time=   1.1s\n",
      "[CV 2/5] END ..max_depth=4, min_samples_leaf=7;, score=-3.188 total time=   0.7s\n",
      "[CV 3/5] END ..max_depth=4, min_samples_leaf=7;, score=-4.464 total time=   0.8s\n",
      "[CV 4/5] END ..max_depth=4, min_samples_leaf=7;, score=-2.652 total time=   0.8s\n",
      "[CV 5/5] END ..max_depth=4, min_samples_leaf=7;, score=-3.483 total time=   0.8s\n",
      "[CV 1/5] END ..max_depth=4, min_samples_leaf=8;, score=-3.459 total time=   0.8s\n",
      "[CV 2/5] END ..max_depth=4, min_samples_leaf=8;, score=-3.188 total time=   1.2s\n",
      "[CV 3/5] END ..max_depth=4, min_samples_leaf=8;, score=-4.464 total time=   1.4s\n",
      "[CV 4/5] END ..max_depth=4, min_samples_leaf=8;, score=-2.769 total time=   1.4s\n",
      "[CV 5/5] END ..max_depth=4, min_samples_leaf=8;, score=-3.483 total time=   1.9s\n",
      "[CV 1/5] END ..max_depth=4, min_samples_leaf=9;, score=-3.459 total time=   2.5s\n",
      "[CV 2/5] END ..max_depth=4, min_samples_leaf=9;, score=-3.188 total time=   1.9s\n",
      "[CV 3/5] END ..max_depth=4, min_samples_leaf=9;, score=-4.464 total time=   1.8s\n",
      "[CV 4/5] END ..max_depth=4, min_samples_leaf=9;, score=-2.769 total time=   2.1s\n",
      "[CV 5/5] END ..max_depth=4, min_samples_leaf=9;, score=-3.483 total time=   1.4s\n",
      "[CV 1/5] END ..max_depth=5, min_samples_leaf=0;, score=-2.969 total time=   1.3s\n",
      "[CV 2/5] END ..max_depth=5, min_samples_leaf=0;, score=-2.869 total time=   1.1s\n",
      "[CV 3/5] END ..max_depth=5, min_samples_leaf=0;, score=-3.709 total time=   1.1s\n",
      "[CV 4/5] END ..max_depth=5, min_samples_leaf=0;, score=-2.553 total time=   1.1s\n",
      "[CV 5/5] END ..max_depth=5, min_samples_leaf=0;, score=-3.803 total time=   1.5s\n",
      "[CV 1/5] END ..max_depth=5, min_samples_leaf=1;, score=-2.969 total time=   1.7s\n",
      "[CV 2/5] END ..max_depth=5, min_samples_leaf=1;, score=-2.869 total time=   1.7s\n",
      "[CV 3/5] END ..max_depth=5, min_samples_leaf=1;, score=-3.709 total time=   1.6s\n",
      "[CV 4/5] END ..max_depth=5, min_samples_leaf=1;, score=-2.553 total time=   1.8s\n",
      "[CV 5/5] END ..max_depth=5, min_samples_leaf=1;, score=-3.803 total time=   1.4s\n",
      "[CV 1/5] END ..max_depth=5, min_samples_leaf=2;, score=-2.933 total time=   1.1s\n",
      "[CV 2/5] END ..max_depth=5, min_samples_leaf=2;, score=-2.898 total time=   1.0s\n",
      "[CV 3/5] END ..max_depth=5, min_samples_leaf=2;, score=-3.703 total time=   1.1s\n",
      "[CV 4/5] END ..max_depth=5, min_samples_leaf=2;, score=-2.452 total time=   1.2s\n",
      "[CV 5/5] END ..max_depth=5, min_samples_leaf=2;, score=-3.569 total time=   1.3s\n",
      "[CV 1/5] END ..max_depth=5, min_samples_leaf=3;, score=-2.962 total time=   1.6s\n",
      "[CV 2/5] END ..max_depth=5, min_samples_leaf=3;, score=-2.898 total time=   1.6s\n",
      "[CV 3/5] END ..max_depth=5, min_samples_leaf=3;, score=-4.365 total time=   1.2s\n",
      "[CV 4/5] END ..max_depth=5, min_samples_leaf=3;, score=-2.603 total time=   1.6s\n",
      "[CV 5/5] END ..max_depth=5, min_samples_leaf=3;, score=-3.569 total time=   1.3s\n",
      "[CV 1/5] END ..max_depth=5, min_samples_leaf=4;, score=-2.962 total time=   1.1s\n",
      "[CV 2/5] END ..max_depth=5, min_samples_leaf=4;, score=-2.898 total time=   1.1s\n",
      "[CV 3/5] END ..max_depth=5, min_samples_leaf=4;, score=-4.659 total time=   0.8s\n",
      "[CV 4/5] END ..max_depth=5, min_samples_leaf=4;, score=-2.590 total time=   1.1s\n",
      "[CV 5/5] END ..max_depth=5, min_samples_leaf=4;, score=-3.474 total time=   1.0s\n",
      "[CV 1/5] END ..max_depth=5, min_samples_leaf=5;, score=-3.291 total time=   1.3s\n",
      "[CV 2/5] END ..max_depth=5, min_samples_leaf=5;, score=-3.188 total time=   1.4s\n",
      "[CV 3/5] END ..max_depth=5, min_samples_leaf=5;, score=-4.659 total time=   1.2s\n",
      "[CV 4/5] END ..max_depth=5, min_samples_leaf=5;, score=-2.590 total time=   1.2s\n",
      "[CV 5/5] END ..max_depth=5, min_samples_leaf=5;, score=-3.474 total time=   1.3s\n",
      "[CV 1/5] END ..max_depth=5, min_samples_leaf=6;, score=-3.291 total time=   1.4s\n",
      "[CV 2/5] END ..max_depth=5, min_samples_leaf=6;, score=-3.148 total time=   1.1s\n",
      "[CV 3/5] END ..max_depth=5, min_samples_leaf=6;, score=-4.659 total time=   0.8s\n",
      "[CV 4/5] END ..max_depth=5, min_samples_leaf=6;, score=-2.590 total time=   0.9s\n",
      "[CV 5/5] END ..max_depth=5, min_samples_leaf=6;, score=-3.499 total time=   0.9s\n",
      "[CV 1/5] END ..max_depth=5, min_samples_leaf=7;, score=-3.358 total time=   0.8s\n",
      "[CV 2/5] END ..max_depth=5, min_samples_leaf=7;, score=-3.148 total time=   0.8s\n",
      "[CV 3/5] END ..max_depth=5, min_samples_leaf=7;, score=-4.502 total time=   1.4s\n",
      "[CV 4/5] END ..max_depth=5, min_samples_leaf=7;, score=-2.590 total time=   1.5s\n",
      "[CV 5/5] END ..max_depth=5, min_samples_leaf=7;, score=-3.499 total time=   1.2s\n",
      "[CV 1/5] END ..max_depth=5, min_samples_leaf=8;, score=-3.376 total time=   1.3s\n",
      "[CV 2/5] END ..max_depth=5, min_samples_leaf=8;, score=-3.148 total time=   1.2s\n",
      "[CV 3/5] END ..max_depth=5, min_samples_leaf=8;, score=-4.520 total time=   1.2s\n",
      "[CV 4/5] END ..max_depth=5, min_samples_leaf=8;, score=-2.707 total time=   1.3s\n",
      "[CV 5/5] END ..max_depth=5, min_samples_leaf=8;, score=-3.499 total time=   1.0s\n",
      "[CV 1/5] END ..max_depth=5, min_samples_leaf=9;, score=-3.376 total time=   0.8s\n",
      "[CV 2/5] END ..max_depth=5, min_samples_leaf=9;, score=-3.148 total time=   0.9s\n",
      "[CV 3/5] END ..max_depth=5, min_samples_leaf=9;, score=-4.520 total time=   1.1s\n",
      "[CV 4/5] END ..max_depth=5, min_samples_leaf=9;, score=-2.707 total time=   1.0s\n",
      "[CV 5/5] END ..max_depth=5, min_samples_leaf=9;, score=-3.499 total time=   1.3s\n",
      "[CV 1/5] END ..max_depth=6, min_samples_leaf=0;, score=-3.035 total time=   2.3s\n",
      "[CV 2/5] END ..max_depth=6, min_samples_leaf=0;, score=-2.938 total time=   2.1s\n",
      "[CV 3/5] END ..max_depth=6, min_samples_leaf=0;, score=-3.624 total time=   2.1s\n",
      "[CV 4/5] END ..max_depth=6, min_samples_leaf=0;, score=-2.622 total time=   2.2s\n",
      "[CV 5/5] END ..max_depth=6, min_samples_leaf=0;, score=-3.414 total time=   1.6s\n",
      "[CV 1/5] END ..max_depth=6, min_samples_leaf=1;, score=-3.035 total time=   1.4s\n",
      "[CV 2/5] END ..max_depth=6, min_samples_leaf=1;, score=-2.938 total time=   1.4s\n",
      "[CV 3/5] END ..max_depth=6, min_samples_leaf=1;, score=-3.624 total time=   1.6s\n",
      "[CV 4/5] END ..max_depth=6, min_samples_leaf=1;, score=-2.622 total time=   2.2s\n",
      "[CV 5/5] END ..max_depth=6, min_samples_leaf=1;, score=-3.414 total time=   2.1s\n",
      "[CV 1/5] END ..max_depth=6, min_samples_leaf=2;, score=-2.955 total time=   1.8s\n",
      "[CV 2/5] END ..max_depth=6, min_samples_leaf=2;, score=-2.791 total time=   2.1s\n",
      "[CV 3/5] END ..max_depth=6, min_samples_leaf=2;, score=-3.655 total time=   1.7s\n",
      "[CV 4/5] END ..max_depth=6, min_samples_leaf=2;, score=-2.533 total time=   1.3s\n",
      "[CV 5/5] END ..max_depth=6, min_samples_leaf=2;, score=-3.568 total time=   1.0s\n",
      "[CV 1/5] END ..max_depth=6, min_samples_leaf=3;, score=-2.978 total time=   1.3s\n",
      "[CV 2/5] END ..max_depth=6, min_samples_leaf=3;, score=-2.749 total time=   1.7s\n",
      "[CV 3/5] END ..max_depth=6, min_samples_leaf=3;, score=-4.338 total time=   1.6s\n",
      "[CV 4/5] END ..max_depth=6, min_samples_leaf=3;, score=-2.595 total time=   1.9s\n",
      "[CV 5/5] END ..max_depth=6, min_samples_leaf=3;, score=-3.525 total time=   1.5s\n",
      "[CV 1/5] END ..max_depth=6, min_samples_leaf=4;, score=-3.001 total time=   2.1s\n",
      "[CV 2/5] END ..max_depth=6, min_samples_leaf=4;, score=-2.749 total time=   1.7s\n",
      "[CV 3/5] END ..max_depth=6, min_samples_leaf=4;, score=-4.582 total time=   0.9s\n",
      "[CV 4/5] END ..max_depth=6, min_samples_leaf=4;, score=-2.516 total time=   1.3s\n",
      "[CV 5/5] END ..max_depth=6, min_samples_leaf=4;, score=-3.425 total time=   1.0s\n",
      "[CV 1/5] END ..max_depth=6, min_samples_leaf=5;, score=-3.352 total time=   1.0s\n",
      "[CV 2/5] END ..max_depth=6, min_samples_leaf=5;, score=-3.188 total time=   1.3s\n",
      "[CV 3/5] END ..max_depth=6, min_samples_leaf=5;, score=-4.683 total time=   1.4s\n",
      "[CV 4/5] END ..max_depth=6, min_samples_leaf=5;, score=-2.605 total time=   1.4s\n",
      "[CV 5/5] END ..max_depth=6, min_samples_leaf=5;, score=-3.425 total time=   1.5s\n",
      "[CV 1/5] END ..max_depth=6, min_samples_leaf=6;, score=-3.352 total time=   1.3s\n",
      "[CV 2/5] END ..max_depth=6, min_samples_leaf=6;, score=-3.148 total time=   1.6s\n",
      "[CV 3/5] END ..max_depth=6, min_samples_leaf=6;, score=-4.668 total time=   1.5s\n",
      "[CV 4/5] END ..max_depth=6, min_samples_leaf=6;, score=-2.605 total time=   1.3s\n",
      "[CV 5/5] END ..max_depth=6, min_samples_leaf=6;, score=-3.499 total time=   1.0s\n",
      "[CV 1/5] END ..max_depth=6, min_samples_leaf=7;, score=-3.419 total time=   1.0s\n",
      "[CV 2/5] END ..max_depth=6, min_samples_leaf=7;, score=-3.148 total time=   0.9s\n",
      "[CV 3/5] END ..max_depth=6, min_samples_leaf=7;, score=-4.511 total time=   1.1s\n",
      "[CV 4/5] END ..max_depth=6, min_samples_leaf=7;, score=-2.605 total time=   1.4s\n",
      "[CV 5/5] END ..max_depth=6, min_samples_leaf=7;, score=-3.499 total time=   1.3s\n",
      "[CV 1/5] END ..max_depth=6, min_samples_leaf=8;, score=-3.360 total time=   1.5s\n",
      "[CV 2/5] END ..max_depth=6, min_samples_leaf=8;, score=-3.148 total time=   1.3s\n",
      "[CV 3/5] END ..max_depth=6, min_samples_leaf=8;, score=-4.529 total time=   1.4s\n",
      "[CV 4/5] END ..max_depth=6, min_samples_leaf=8;, score=-2.722 total time=   1.4s\n",
      "[CV 5/5] END ..max_depth=6, min_samples_leaf=8;, score=-3.499 total time=   1.1s\n",
      "[CV 1/5] END ..max_depth=6, min_samples_leaf=9;, score=-3.376 total time=   0.9s\n",
      "[CV 2/5] END ..max_depth=6, min_samples_leaf=9;, score=-3.148 total time=   0.9s\n",
      "[CV 3/5] END ..max_depth=6, min_samples_leaf=9;, score=-4.529 total time=   0.9s\n",
      "[CV 4/5] END ..max_depth=6, min_samples_leaf=9;, score=-2.707 total time=   0.9s\n",
      "[CV 5/5] END ..max_depth=6, min_samples_leaf=9;, score=-3.499 total time=   1.1s\n",
      "[CV 1/5] END ..max_depth=7, min_samples_leaf=0;, score=-3.159 total time=   2.4s\n",
      "[CV 2/5] END ..max_depth=7, min_samples_leaf=0;, score=-3.006 total time=   2.4s\n",
      "[CV 3/5] END ..max_depth=7, min_samples_leaf=0;, score=-3.682 total time=   2.3s\n",
      "[CV 4/5] END ..max_depth=7, min_samples_leaf=0;, score=-2.445 total time=   2.3s\n",
      "[CV 5/5] END ..max_depth=7, min_samples_leaf=0;, score=-3.315 total time=   1.6s\n",
      "[CV 1/5] END ..max_depth=7, min_samples_leaf=1;, score=-3.159 total time=   1.6s\n",
      "[CV 2/5] END ..max_depth=7, min_samples_leaf=1;, score=-3.006 total time=   1.7s\n",
      "[CV 3/5] END ..max_depth=7, min_samples_leaf=1;, score=-3.682 total time=   2.4s\n",
      "[CV 4/5] END ..max_depth=7, min_samples_leaf=1;, score=-2.445 total time=   2.5s\n",
      "[CV 5/5] END ..max_depth=7, min_samples_leaf=1;, score=-3.315 total time=   2.4s\n",
      "[CV 1/5] END ..max_depth=7, min_samples_leaf=2;, score=-2.941 total time=   2.3s\n",
      "[CV 2/5] END ..max_depth=7, min_samples_leaf=2;, score=-2.900 total time=   1.6s\n",
      "[CV 3/5] END ..max_depth=7, min_samples_leaf=2;, score=-3.686 total time=   1.5s\n",
      "[CV 4/5] END ..max_depth=7, min_samples_leaf=2;, score=-2.509 total time=   1.5s\n",
      "[CV 5/5] END ..max_depth=7, min_samples_leaf=2;, score=-3.464 total time=   1.6s\n",
      "[CV 1/5] END ..max_depth=7, min_samples_leaf=3;, score=-2.978 total time=   2.3s\n",
      "[CV 2/5] END ..max_depth=7, min_samples_leaf=3;, score=-2.701 total time=   2.1s\n",
      "[CV 3/5] END ..max_depth=7, min_samples_leaf=3;, score=-4.349 total time=   1.4s\n",
      "[CV 4/5] END ..max_depth=7, min_samples_leaf=3;, score=-2.516 total time=   2.2s\n",
      "[CV 5/5] END ..max_depth=7, min_samples_leaf=3;, score=-3.384 total time=   1.3s\n",
      "[CV 1/5] END ..max_depth=7, min_samples_leaf=4;, score=-3.004 total time=   1.5s\n",
      "[CV 2/5] END ..max_depth=7, min_samples_leaf=4;, score=-2.701 total time=   1.4s\n",
      "[CV 3/5] END ..max_depth=7, min_samples_leaf=4;, score=-4.593 total time=   0.9s\n",
      "[CV 4/5] END ..max_depth=7, min_samples_leaf=4;, score=-2.424 total time=   2.0s\n",
      "[CV 5/5] END ..max_depth=7, min_samples_leaf=4;, score=-3.272 total time=   1.6s\n",
      "[CV 1/5] END ..max_depth=7, min_samples_leaf=5;, score=-3.333 total time=   1.6s\n",
      "[CV 2/5] END ..max_depth=7, min_samples_leaf=5;, score=-3.162 total time=   1.4s\n",
      "[CV 3/5] END ..max_depth=7, min_samples_leaf=5;, score=-4.694 total time=   1.5s\n",
      "[CV 4/5] END ..max_depth=7, min_samples_leaf=5;, score=-2.605 total time=   1.4s\n",
      "[CV 5/5] END ..max_depth=7, min_samples_leaf=5;, score=-3.338 total time=   1.1s\n",
      "[CV 1/5] END ..max_depth=7, min_samples_leaf=6;, score=-3.352 total time=   1.0s\n",
      "[CV 2/5] END ..max_depth=7, min_samples_leaf=6;, score=-3.148 total time=   1.0s\n",
      "[CV 3/5] END ..max_depth=7, min_samples_leaf=6;, score=-4.668 total time=   1.0s\n",
      "[CV 4/5] END ..max_depth=7, min_samples_leaf=6;, score=-2.605 total time=   1.0s\n",
      "[CV 5/5] END ..max_depth=7, min_samples_leaf=6;, score=-3.499 total time=   1.3s\n",
      "[CV 1/5] END ..max_depth=7, min_samples_leaf=7;, score=-3.419 total time=   1.7s\n",
      "[CV 2/5] END ..max_depth=7, min_samples_leaf=7;, score=-3.148 total time=   1.6s\n",
      "[CV 3/5] END ..max_depth=7, min_samples_leaf=7;, score=-4.511 total time=   1.3s\n",
      "[CV 4/5] END ..max_depth=7, min_samples_leaf=7;, score=-2.605 total time=   1.5s\n",
      "[CV 5/5] END ..max_depth=7, min_samples_leaf=7;, score=-3.499 total time=   1.4s\n",
      "[CV 1/5] END ..max_depth=7, min_samples_leaf=8;, score=-3.360 total time=   1.3s\n",
      "[CV 2/5] END ..max_depth=7, min_samples_leaf=8;, score=-3.148 total time=   0.9s\n",
      "[CV 3/5] END ..max_depth=7, min_samples_leaf=8;, score=-4.529 total time=   0.9s\n",
      "[CV 4/5] END ..max_depth=7, min_samples_leaf=8;, score=-2.722 total time=   1.0s\n",
      "[CV 5/5] END ..max_depth=7, min_samples_leaf=8;, score=-3.499 total time=   0.9s\n",
      "[CV 1/5] END ..max_depth=7, min_samples_leaf=9;, score=-3.376 total time=   1.1s\n",
      "[CV 2/5] END ..max_depth=7, min_samples_leaf=9;, score=-3.148 total time=   1.3s\n",
      "[CV 3/5] END ..max_depth=7, min_samples_leaf=9;, score=-4.529 total time=   1.5s\n",
      "[CV 4/5] END ..max_depth=7, min_samples_leaf=9;, score=-2.707 total time=   1.5s\n",
      "[CV 5/5] END ..max_depth=7, min_samples_leaf=9;, score=-3.499 total time=   1.3s\n",
      "[CV 1/5] END ..max_depth=8, min_samples_leaf=0;, score=-3.249 total time=   2.7s\n",
      "[CV 2/5] END ..max_depth=8, min_samples_leaf=0;, score=-3.164 total time=   2.2s\n",
      "[CV 3/5] END ..max_depth=8, min_samples_leaf=0;, score=-3.639 total time=   1.8s\n",
      "[CV 4/5] END ..max_depth=8, min_samples_leaf=0;, score=-2.595 total time=   1.8s\n",
      "[CV 5/5] END ..max_depth=8, min_samples_leaf=0;, score=-3.418 total time=   2.5s\n",
      "[CV 1/5] END ..max_depth=8, min_samples_leaf=1;, score=-3.249 total time=   2.7s\n",
      "[CV 2/5] END ..max_depth=8, min_samples_leaf=1;, score=-3.164 total time=   2.7s\n",
      "[CV 3/5] END ..max_depth=8, min_samples_leaf=1;, score=-3.639 total time=   2.3s\n",
      "[CV 4/5] END ..max_depth=8, min_samples_leaf=1;, score=-2.595 total time=   1.8s\n",
      "[CV 5/5] END ..max_depth=8, min_samples_leaf=1;, score=-3.418 total time=   1.8s\n",
      "[CV 1/5] END ..max_depth=8, min_samples_leaf=2;, score=-2.912 total time=   2.0s\n",
      "[CV 2/5] END ..max_depth=8, min_samples_leaf=2;, score=-2.926 total time=   2.5s\n",
      "[CV 3/5] END ..max_depth=8, min_samples_leaf=2;, score=-3.729 total time=   2.3s\n",
      "[CV 4/5] END ..max_depth=8, min_samples_leaf=2;, score=-2.528 total time=   2.6s\n",
      "[CV 5/5] END ..max_depth=8, min_samples_leaf=2;, score=-3.443 total time=   1.5s\n",
      "[CV 1/5] END ..max_depth=8, min_samples_leaf=3;, score=-2.957 total time=   1.5s\n",
      "[CV 2/5] END ..max_depth=8, min_samples_leaf=3;, score=-2.750 total time=   1.5s\n",
      "[CV 3/5] END ..max_depth=8, min_samples_leaf=3;, score=-4.349 total time=   1.0s\n",
      "[CV 4/5] END ..max_depth=8, min_samples_leaf=3;, score=-2.574 total time=   2.0s\n",
      "[CV 5/5] END ..max_depth=8, min_samples_leaf=3;, score=-3.326 total time=   1.8s\n",
      "[CV 1/5] END ..max_depth=8, min_samples_leaf=4;, score=-3.004 total time=   2.0s\n",
      "[CV 2/5] END ..max_depth=8, min_samples_leaf=4;, score=-2.748 total time=   2.2s\n",
      "[CV 3/5] END ..max_depth=8, min_samples_leaf=4;, score=-4.593 total time=   1.5s\n",
      "[CV 4/5] END ..max_depth=8, min_samples_leaf=4;, score=-2.424 total time=   1.6s\n",
      "[CV 5/5] END ..max_depth=8, min_samples_leaf=4;, score=-3.215 total time=   1.0s\n",
      "[CV 1/5] END ..max_depth=8, min_samples_leaf=5;, score=-3.333 total time=   1.0s\n",
      "[CV 2/5] END ..max_depth=8, min_samples_leaf=5;, score=-3.157 total time=   1.0s\n",
      "[CV 3/5] END ..max_depth=8, min_samples_leaf=5;, score=-4.694 total time=   1.1s\n",
      "[CV 4/5] END ..max_depth=8, min_samples_leaf=5;, score=-2.605 total time=   1.5s\n",
      "[CV 5/5] END ..max_depth=8, min_samples_leaf=5;, score=-3.338 total time=   1.7s\n",
      "[CV 1/5] END ..max_depth=8, min_samples_leaf=6;, score=-3.352 total time=   1.7s\n",
      "[CV 2/5] END ..max_depth=8, min_samples_leaf=6;, score=-3.148 total time=   1.3s\n",
      "[CV 3/5] END ..max_depth=8, min_samples_leaf=6;, score=-4.668 total time=   1.5s\n",
      "[CV 4/5] END ..max_depth=8, min_samples_leaf=6;, score=-2.605 total time=   1.4s\n",
      "[CV 5/5] END ..max_depth=8, min_samples_leaf=6;, score=-3.499 total time=   1.0s\n",
      "[CV 1/5] END ..max_depth=8, min_samples_leaf=7;, score=-3.419 total time=   1.3s\n",
      "[CV 2/5] END ..max_depth=8, min_samples_leaf=7;, score=-3.148 total time=   1.5s\n",
      "[CV 3/5] END ..max_depth=8, min_samples_leaf=7;, score=-4.511 total time=   1.1s\n",
      "[CV 4/5] END ..max_depth=8, min_samples_leaf=7;, score=-2.605 total time=   1.5s\n",
      "[CV 5/5] END ..max_depth=8, min_samples_leaf=7;, score=-3.499 total time=   1.4s\n",
      "[CV 1/5] END ..max_depth=8, min_samples_leaf=8;, score=-3.360 total time=   1.4s\n",
      "[CV 2/5] END ..max_depth=8, min_samples_leaf=8;, score=-3.148 total time=   1.4s\n",
      "[CV 3/5] END ..max_depth=8, min_samples_leaf=8;, score=-4.529 total time=   1.5s\n",
      "[CV 4/5] END ..max_depth=8, min_samples_leaf=8;, score=-2.722 total time=   1.4s\n",
      "[CV 5/5] END ..max_depth=8, min_samples_leaf=8;, score=-3.499 total time=   1.3s\n",
      "[CV 1/5] END ..max_depth=8, min_samples_leaf=9;, score=-3.376 total time=   1.0s\n",
      "[CV 2/5] END ..max_depth=8, min_samples_leaf=9;, score=-3.148 total time=   0.9s\n",
      "[CV 3/5] END ..max_depth=8, min_samples_leaf=9;, score=-4.529 total time=   1.1s\n",
      "[CV 4/5] END ..max_depth=8, min_samples_leaf=9;, score=-2.707 total time=   1.1s\n",
      "[CV 5/5] END ..max_depth=8, min_samples_leaf=9;, score=-3.499 total time=   1.1s\n",
      "[CV 1/5] END ..max_depth=9, min_samples_leaf=0;, score=-3.264 total time=   2.9s\n",
      "[CV 2/5] END ..max_depth=9, min_samples_leaf=0;, score=-3.194 total time=   2.8s\n",
      "[CV 3/5] END ..max_depth=9, min_samples_leaf=0;, score=-3.723 total time=   2.9s\n",
      "[CV 4/5] END ..max_depth=9, min_samples_leaf=0;, score=-2.563 total time=   2.1s\n",
      "[CV 5/5] END ..max_depth=9, min_samples_leaf=0;, score=-3.473 total time=   1.9s\n",
      "[CV 1/5] END ..max_depth=9, min_samples_leaf=1;, score=-3.264 total time=   2.3s\n",
      "[CV 2/5] END ..max_depth=9, min_samples_leaf=1;, score=-3.194 total time=   2.9s\n",
      "[CV 3/5] END ..max_depth=9, min_samples_leaf=1;, score=-3.723 total time=   2.9s\n",
      "[CV 4/5] END ..max_depth=9, min_samples_leaf=1;, score=-2.563 total time=   3.0s\n",
      "[CV 5/5] END ..max_depth=9, min_samples_leaf=1;, score=-3.473 total time=   2.0s\n",
      "[CV 1/5] END ..max_depth=9, min_samples_leaf=2;, score=-2.860 total time=   1.6s\n",
      "[CV 2/5] END ..max_depth=9, min_samples_leaf=2;, score=-2.989 total time=   2.1s\n",
      "[CV 3/5] END ..max_depth=9, min_samples_leaf=2;, score=-3.821 total time=   2.5s\n",
      "[CV 4/5] END ..max_depth=9, min_samples_leaf=2;, score=-2.525 total time=   2.6s\n",
      "[CV 5/5] END ..max_depth=9, min_samples_leaf=2;, score=-3.438 total time=   1.9s\n",
      "[CV 1/5] END ..max_depth=9, min_samples_leaf=3;, score=-2.957 total time=   2.2s\n",
      "[CV 2/5] END ..max_depth=9, min_samples_leaf=3;, score=-2.789 total time=   1.6s\n",
      "[CV 3/5] END ..max_depth=9, min_samples_leaf=3;, score=-4.349 total time=   1.0s\n",
      "[CV 4/5] END ..max_depth=9, min_samples_leaf=3;, score=-2.574 total time=   1.6s\n",
      "[CV 5/5] END ..max_depth=9, min_samples_leaf=3;, score=-3.306 total time=   1.5s\n",
      "[CV 1/5] END ..max_depth=9, min_samples_leaf=4;, score=-3.004 total time=   2.1s\n",
      "[CV 2/5] END ..max_depth=9, min_samples_leaf=4;, score=-2.773 total time=   2.5s\n",
      "[CV 3/5] END ..max_depth=9, min_samples_leaf=4;, score=-4.593 total time=   1.4s\n",
      "[CV 4/5] END ..max_depth=9, min_samples_leaf=4;, score=-2.424 total time=   2.4s\n",
      "[CV 5/5] END ..max_depth=9, min_samples_leaf=4;, score=-3.199 total time=   1.2s\n",
      "[CV 1/5] END ..max_depth=9, min_samples_leaf=5;, score=-3.333 total time=   1.0s\n",
      "[CV 2/5] END ..max_depth=9, min_samples_leaf=5;, score=-3.157 total time=   1.0s\n",
      "[CV 3/5] END ..max_depth=9, min_samples_leaf=5;, score=-4.694 total time=   1.0s\n",
      "[CV 4/5] END ..max_depth=9, min_samples_leaf=5;, score=-2.605 total time=   1.1s\n",
      "[CV 5/5] END ..max_depth=9, min_samples_leaf=5;, score=-3.338 total time=   1.5s\n",
      "[CV 1/5] END ..max_depth=9, min_samples_leaf=6;, score=-3.352 total time=   1.5s\n",
      "[CV 2/5] END ..max_depth=9, min_samples_leaf=6;, score=-3.148 total time=   1.5s\n",
      "[CV 3/5] END ..max_depth=9, min_samples_leaf=6;, score=-4.668 total time=   1.3s\n",
      "[CV 4/5] END ..max_depth=9, min_samples_leaf=6;, score=-2.605 total time=   1.5s\n",
      "[CV 5/5] END ..max_depth=9, min_samples_leaf=6;, score=-3.499 total time=   1.4s\n",
      "[CV 1/5] END ..max_depth=9, min_samples_leaf=7;, score=-3.419 total time=   1.2s\n",
      "[CV 2/5] END ..max_depth=9, min_samples_leaf=7;, score=-3.148 total time=   0.9s\n",
      "[CV 3/5] END ..max_depth=9, min_samples_leaf=7;, score=-4.511 total time=   0.9s\n",
      "[CV 4/5] END ..max_depth=9, min_samples_leaf=7;, score=-2.605 total time=   1.0s\n",
      "[CV 5/5] END ..max_depth=9, min_samples_leaf=7;, score=-3.499 total time=   0.9s\n",
      "[CV 1/5] END ..max_depth=9, min_samples_leaf=8;, score=-3.360 total time=   1.3s\n",
      "[CV 2/5] END ..max_depth=9, min_samples_leaf=8;, score=-3.148 total time=   1.4s\n",
      "[CV 3/5] END ..max_depth=9, min_samples_leaf=8;, score=-4.529 total time=   1.4s\n",
      "[CV 4/5] END ..max_depth=9, min_samples_leaf=8;, score=-2.722 total time=   1.5s\n",
      "[CV 5/5] END ..max_depth=9, min_samples_leaf=8;, score=-3.499 total time=   1.3s\n",
      "[CV 1/5] END ..max_depth=9, min_samples_leaf=9;, score=-3.376 total time=   1.5s\n",
      "[CV 2/5] END ..max_depth=9, min_samples_leaf=9;, score=-3.148 total time=   1.4s\n",
      "[CV 3/5] END ..max_depth=9, min_samples_leaf=9;, score=-4.529 total time=   1.0s\n",
      "[CV 4/5] END ..max_depth=9, min_samples_leaf=9;, score=-2.707 total time=   1.0s\n",
      "[CV 5/5] END ..max_depth=9, min_samples_leaf=9;, score=-3.499 total time=   0.9s\n",
      " : {'max_depth': 7, 'min_samples_leaf': 2} \n",
      "\n",
      " : -3.099878874908554 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"max_depth\":range(0,10),'min_samples_leaf':range(0,10)}\n",
    "model = MyDecisionTreeRegressor()\n",
    "grid = GridSearchCV(model, parameters, scoring='neg_mean_absolute_error', verbose=4)\n",
    "grid.fit(features_train, target_train)\n",
    "print(' :', grid.best_params_, '\\n')\n",
    "print(' :', grid.best_score_, '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 6 <a id=\"task6\"></a>  (2 points)\n",
    "\n",
    "Recall definition of bias and variance:\n",
    "$$\n",
    "\\text{Bias}^2 = \\mathbb{E}_{p(x, y)} \\left[  (f(x) - \\mathbb{E}_{\\mathbb{X}}a_{\\mathbb{X}}(x))^2 \\right] \\\\\n",
    "\\text{Variance} = \\mathbb{E}_{p(x, y)} \\left[  \\mathbb{V}_{\\mathbb{X}}( a_{\\mathbb{X}}(x))  \\right]\n",
    "$$\n",
    "\n",
    "We wil now use use the following algorithm to estimate bias and variance:\n",
    "\n",
    "1. Use bootsrap to create `n_iter` samples from the original dataset: $X_1, \\dots, X_{n_iter}$\n",
    "2. For each bootstrapped sample define out-of-bag (OOB) sample $Z_1, \\dots, Z_{n_iter}$, which contain all the observations, which did not appear in the corresponding boostraped sample\n",
    "3. Fit the model on $X_i$s and compute predictions on $Z_i$s\n",
    "4. For a given *object* $n$:\n",
    "     - bias^2: squared difference between true value $y_n$ and average prediction (average over the algorithms, for which $n$ was in OOB)\n",
    "     - variance: variance of the prediction (predictions of the algorithms, for which $n$ was in OOB)\n",
    "5. Average bias^2 and variance over all the points\n",
    "\n",
    "**Implement `get_bias_variance` function, using the algorithm above**\n",
    "\n",
    "*Note:*  You can only use 1 loop (for bootsrap iterations). All other operations should be vectorized."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "def get_bias_variance(estimator, x, y, n_iter):\n",
    "    \"\"\"\n",
    "    Calculate bias and variance of the `estimator`.\n",
    "    Using a given dataset and bootstrap with `n_iter` samples.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : ndarray, shape (n_samples, n_features)\n",
    "        The input samples.\n",
    "    y : ndarray, shape (n_samples, n_features)\n",
    "        The input samples.\n",
    "    n_iter: int\n",
    "        Number of samples in\n",
    "    Returns\n",
    "    -------\n",
    "    bias2 : float,\n",
    "        Estiamted squared bias\n",
    "    variance : float,\n",
    "        Estiamted variance\n",
    "    \"\"\"\n",
    "    np.random.seed(12345)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #TypeError: only integer scalar arrays can be converted to a scalar index\n",
    "    data_tmp = pd.DataFrame([], index=range(len(y)))\n",
    "    # for i in range(n_iter):\n",
    "    #     data_tmp[i] = np.nan\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        bootstrap = np.random.choice(len(y), len(y))\n",
    "\n",
    "        OOB_indexes = np.arange(len(y))[~np.isin(np.arange(len(y)),bootstrap)]\n",
    "        OOB = x[OOB_indexes, :]\n",
    "\n",
    "        estimator.fit(x[bootstrap, :], y[bootstrap])\n",
    "        predictions = estimator.predict(OOB)\n",
    "\n",
    "        columns = pd.Series([np.nan] * len(y))\n",
    "        columns = np.array(columns)\n",
    "\n",
    "        np.put(columns, OOB_indexes, predictions)\n",
    "\n",
    "        # display(pd.Series(columns))\n",
    "\n",
    "        # display(pd.Series(columns))\n",
    "        data_tmp[i] = pd.Series(columns)\n",
    "\n",
    "\n",
    "        #Note: You can only use 1 loop (for bootsrap iterations). All other operations should be vectorized.Note: You can only use 1 loop (for bootsrap iterations). All other operations should be vectorized.\n",
    "        # for index in data_tmp.index:\n",
    "        #     if index in OOB_indexes:\n",
    "        #         data_tmp.loc[index, i] = predictions[index]\n",
    "        # display(data_tmp)\n",
    "        # my_iter = iter(predictions)\n",
    "        # print(OOB_indexes)\n",
    "        # for j in range(len(y)):\n",
    "        #     if j in OOB_indexes:\n",
    "        #         print('J', j)\n",
    "        #         index = list(OOB_indexes).index(j)\n",
    "        #         print('INDEX', index)\n",
    "        #         data_tmp.at[i, index] = next(my_iter)\n",
    "        # display(data_tmp)\n",
    "\n",
    "\n",
    "    return np.nanmean(np.square(y - np.nanmean(data_tmp, axis = 1))), np.nanmean(np.nanvar(data_tmp, axis=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_23820\\4179258945.py:65: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(np.square(y - np.nanmean(data_tmp, axis = 1))), np.nanmean(np.nanvar(data_tmp, axis=1))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_23820\\4179258945.py:65: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  return np.nanmean(np.square(y - np.nanmean(data_tmp, axis = 1))), np.nanmean(np.nanvar(data_tmp, axis=1))\n"
     ]
    },
    {
     "data": {
      "text/plain": "(19.095601269187487, 8.24848465600325)"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "estimator = MyDecisionTreeRegressor(max_depth=8, min_samples_split=15)\n",
    "\n",
    "get_bias_variance(estimator, features_train, target_train, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 7 <a id=\"task7\"></a>  (0.5 points)\n",
    "\n",
    "Compute bias and variance for the trees with different min_samples_split. Plot how bias and variance change as min_samples_split increases.\n",
    "\n",
    "Comment on what you observe, how does your result correspond to theory?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_23820\\4179258945.py:65: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(np.square(y - np.nanmean(data_tmp, axis = 1))), np.nanmean(np.nanvar(data_tmp, axis=1))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_23820\\4179258945.py:65: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  return np.nanmean(np.square(y - np.nanmean(data_tmp, axis = 1))), np.nanmean(np.nanvar(data_tmp, axis=1))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_23820\\4179258945.py:65: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(np.square(y - np.nanmean(data_tmp, axis = 1))), np.nanmean(np.nanvar(data_tmp, axis=1))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_23820\\4179258945.py:65: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  return np.nanmean(np.square(y - np.nanmean(data_tmp, axis = 1))), np.nanmean(np.nanvar(data_tmp, axis=1))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_23820\\4179258945.py:65: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(np.square(y - np.nanmean(data_tmp, axis = 1))), np.nanmean(np.nanvar(data_tmp, axis=1))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_23820\\4179258945.py:65: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  return np.nanmean(np.square(y - np.nanmean(data_tmp, axis = 1))), np.nanmean(np.nanvar(data_tmp, axis=1))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_23820\\4179258945.py:65: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(np.square(y - np.nanmean(data_tmp, axis = 1))), np.nanmean(np.nanvar(data_tmp, axis=1))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_23820\\4179258945.py:65: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  return np.nanmean(np.square(y - np.nanmean(data_tmp, axis = 1))), np.nanmean(np.nanvar(data_tmp, axis=1))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_23820\\4179258945.py:65: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(np.square(y - np.nanmean(data_tmp, axis = 1))), np.nanmean(np.nanvar(data_tmp, axis=1))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_23820\\4179258945.py:65: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  return np.nanmean(np.square(y - np.nanmean(data_tmp, axis = 1))), np.nanmean(np.nanvar(data_tmp, axis=1))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_23820\\4179258945.py:65: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(np.square(y - np.nanmean(data_tmp, axis = 1))), np.nanmean(np.nanvar(data_tmp, axis=1))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_23820\\4179258945.py:65: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  return np.nanmean(np.square(y - np.nanmean(data_tmp, axis = 1))), np.nanmean(np.nanvar(data_tmp, axis=1))\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "\n",
    "bias_lst = []\n",
    "variance_lst = []\n",
    "\n",
    "for sample in range(0, 51, 10):\n",
    "    model = MyDecisionTreeRegressor(max_depth=10, min_samples_split=sample)\n",
    "    bias, variance = get_bias_variance(model, features_train, target_train, 10)\n",
    "    bias_lst.append(bias)\n",
    "    variance_lst.append(variance)\n",
    "plt.plot(range(0, 51, 10), bias_lst, label='bias')\n",
    "plt.plot(range(0, 51, 10), variance_lst, label='variance')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "```     ,      target.   min_samples_split  \"\"   variance  (  ). ,     ,      bias     .```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 8 <a id=\"task8\"></a>  (0.5 points)\n",
    "\n",
    "Let's try to reduce variance with bagging. Use `sklearn.ensemble.BaggingRegressor` to get an ensemble and compute its bias and variance.\n",
    "\n",
    "Answer the following questions:\n",
    " - How bagging should affect bias and variance in theory?\n",
    " - How bias and variance change (if they change) compared to an individual tree in you experiments?\n",
    " - Do your results align with the theory? Why?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_23820\\4179258945.py:65: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(np.square(y - np.nanmean(data_tmp, axis = 1))), np.nanmean(np.nanvar(data_tmp, axis=1))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_23820\\4179258945.py:65: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  return np.nanmean(np.square(y - np.nanmean(data_tmp, axis = 1))), np.nanmean(np.nanvar(data_tmp, axis=1))\n"
     ]
    },
    {
     "data": {
      "text/plain": "(17.559494587243048, 2.668438761355124)"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "model = BaggingRegressor(base_estimator=MyDecisionTreeRegressor(max_depth=8, min_samples_split=15), n_estimators=10, random_state=12345)\n",
    "\n",
    "get_bias_variance(model, features_train, target_train, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 2. More Ensembles"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "      age sex on_thyroxine query_on_thyroxine on_antithyroid_medication sick  \\\n0    41.0   F            f                  f                         f    f   \n1    23.0   F            f                  f                         f    f   \n2    46.0   M            f                  f                         f    f   \n3    70.0   F            t                  f                         f    f   \n4    70.0   F            f                  f                         f    f   \n..    ...  ..          ...                ...                       ...  ...   \n995  34.0   F            f                  f                         t    f   \n996  72.0   F            f                  f                         f    f   \n997  34.0   F            f                  f                         f    f   \n998  32.0   F            f                  f                         f    f   \n999  63.0   F            t                  f                         f    f   \n\n    pregnant thyroid_surgery I131_treatment query_hypothyroid  ...   T3  \\\n0          f               f              f                 f  ...  2.5   \n1          f               f              f                 f  ...  2.0   \n2          f               f              f                 f  ...  NaN   \n3          f               f              f                 f  ...  1.9   \n4          f               f              f                 f  ...  1.2   \n..       ...             ...            ...               ...  ...  ...   \n995        t               f              f                 f  ...  3.8   \n996        f               f              f                 f  ...  1.9   \n997        f               f              f                 f  ...  2.3   \n998        f               f              f                 f  ...  NaN   \n999        f               f              f                 f  ...  NaN   \n\n    TT4_measured    TT4 T4U_measured   T4U FTI_measured    FTI  TBG_measured  \\\n0              t  125.0            t  1.14            t  109.0             f   \n1              t  102.0            f   NaN            f    NaN             f   \n2              t  109.0            t  0.91            t  120.0             f   \n3              t  175.0            f   NaN            f    NaN             f   \n4              t   61.0            t  0.87            t   70.0             f   \n..           ...    ...          ...   ...          ...    ...           ...   \n995            t  205.0            t  1.84            t  111.0             f   \n996            t  141.0            t  1.09            t  129.0             f   \n997            t  139.0            t  1.06            t  131.0             f   \n998            f    NaN            f   NaN            f    NaN             f   \n999            t  166.0            t  0.97            t  170.0             f   \n\n    TBG  referral_source  \n0   NaN             SVHC  \n1   NaN            other  \n2   NaN            other  \n3   NaN            other  \n4   NaN              SVI  \n..   ..              ...  \n995 NaN             STMW  \n996 NaN            other  \n997 NaN            other  \n998 NaN            other  \n999 NaN            other  \n\n[1000 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>on_thyroxine</th>\n      <th>query_on_thyroxine</th>\n      <th>on_antithyroid_medication</th>\n      <th>sick</th>\n      <th>pregnant</th>\n      <th>thyroid_surgery</th>\n      <th>I131_treatment</th>\n      <th>query_hypothyroid</th>\n      <th>...</th>\n      <th>T3</th>\n      <th>TT4_measured</th>\n      <th>TT4</th>\n      <th>T4U_measured</th>\n      <th>T4U</th>\n      <th>FTI_measured</th>\n      <th>FTI</th>\n      <th>TBG_measured</th>\n      <th>TBG</th>\n      <th>referral_source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>41.0</td>\n      <td>F</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>...</td>\n      <td>2.5</td>\n      <td>t</td>\n      <td>125.0</td>\n      <td>t</td>\n      <td>1.14</td>\n      <td>t</td>\n      <td>109.0</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>SVHC</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>23.0</td>\n      <td>F</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>t</td>\n      <td>102.0</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>other</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>46.0</td>\n      <td>M</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>t</td>\n      <td>109.0</td>\n      <td>t</td>\n      <td>0.91</td>\n      <td>t</td>\n      <td>120.0</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>other</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70.0</td>\n      <td>F</td>\n      <td>t</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>...</td>\n      <td>1.9</td>\n      <td>t</td>\n      <td>175.0</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>other</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>70.0</td>\n      <td>F</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>...</td>\n      <td>1.2</td>\n      <td>t</td>\n      <td>61.0</td>\n      <td>t</td>\n      <td>0.87</td>\n      <td>t</td>\n      <td>70.0</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>SVI</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>34.0</td>\n      <td>F</td>\n      <td>f</td>\n      <td>f</td>\n      <td>t</td>\n      <td>f</td>\n      <td>t</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>...</td>\n      <td>3.8</td>\n      <td>t</td>\n      <td>205.0</td>\n      <td>t</td>\n      <td>1.84</td>\n      <td>t</td>\n      <td>111.0</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>STMW</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>72.0</td>\n      <td>F</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>...</td>\n      <td>1.9</td>\n      <td>t</td>\n      <td>141.0</td>\n      <td>t</td>\n      <td>1.09</td>\n      <td>t</td>\n      <td>129.0</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>other</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>34.0</td>\n      <td>F</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>...</td>\n      <td>2.3</td>\n      <td>t</td>\n      <td>139.0</td>\n      <td>t</td>\n      <td>1.06</td>\n      <td>t</td>\n      <td>131.0</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>other</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>32.0</td>\n      <td>F</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>other</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>63.0</td>\n      <td>F</td>\n      <td>t</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>t</td>\n      <td>166.0</td>\n      <td>t</td>\n      <td>0.97</td>\n      <td>t</td>\n      <td>170.0</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>other</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows  29 columns</p>\n</div>"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('D:/PY/dsProject1/thyroid_disease.csv')\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['Class'])\n",
    "X = df.drop('Class', axis=1)\n",
    "X.head(1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 1 <a id=\"task2_1\"></a> (1 point)\n",
    "\n",
    "Let's start with data preprocessing.\n",
    "\n",
    "0. Drop columns, which are not usefull (e.g. a lot of missing values). Motivate your choice.\n",
    "1. Split dataset into train and test\n",
    "2. You've probably noticed that we have both categorical and numerical columns. Here is what you need to do with them:\n",
    "    - Categorical: Fill missing values and apply one-hot-encoding\n",
    "    - Numeric: Fill missing values\n",
    "\n",
    "Use `ColumnTranformer` to define a single transformer for all the columns in the dataset. It takes as input a list of tuples\n",
    "\n",
    "```\n",
    "ColumnTransformer([\n",
    "    ('name1', transform1, column_names1),\n",
    "    ('name2', transform2, column_names2)\n",
    "])\n",
    "```\n",
    "\n",
    "Pay attention to an argument `remainder='passthrough'`. [Here](https://scikit-learn.org/stable/modules/compose.html#column-transformer) you can find some examples of how to use column transformer.\n",
    "\n",
    "Since we want to apply 2 transformations to categorical feature, it is very convenient to combine them into a `Pipeline`:\n",
    "\n",
    "```\n",
    "double_tranform = make_pipeline(\n",
    "                        transform_1,\n",
    "                        transform_2\n",
    "                        )\n",
    "```\n",
    "\n",
    "P.S. Choose your favourite way to fill missing values.\n",
    "\n",
    "*Hint* Categorical column usually have `dtype = 'object'`. This may help to obtain list of categorical and numerical columns on the dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "age                             1\nsex                           150\non_thyroxine                    0\nquery_on_thyroxine              0\non_antithyroid_medication       0\nsick                            0\npregnant                        0\nthyroid_surgery                 0\nI131_treatment                  0\nquery_hypothyroid               0\nquery_hyperthyroid              0\nlithium                         0\ngoitre                          0\ntumor                           0\nhypopituitary                   0\npsych                           0\nTSH_measured                    0\nTSH                           369\nT3_measured                     0\nT3                            769\nTT4_measured                    0\nTT4                           231\nT4U_measured                    0\nT4U                           387\nFTI_measured                    0\nFTI                           385\nTBG_measured                    0\nTBG                          3772\nreferral_source                 0\ndtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.9766702]\n",
      "[9.7826087]\n",
      "[20.38706257]\n",
      "[6.12407211]\n",
      "[10.25980912]\n",
      "[10.20678685]\n",
      "[100.]\n"
     ]
    }
   ],
   "source": [
    "print(X['sex'].isnull().sum()/X['sex'].shape*100)\n",
    "print(X['TSH'].isnull().sum()/X['TSH'].shape*100)\n",
    "print(X['T3'].isnull().sum()/X['T3'].shape*100)\n",
    "print(X['TT4'].isnull().sum()/X['TT4'].shape*100)\n",
    "print(X['T4U'].isnull().sum()/X['T4U'].shape*100)\n",
    "print(X['FTI'].isnull().sum()/X['FTI'].shape*100)\n",
    "print(X['TBG'].isnull().sum()/X['TBG'].shape*100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "data": {
      "text/plain": "age                             1\nsex                           150\non_thyroxine                    0\nquery_on_thyroxine              0\non_antithyroid_medication       0\nsick                            0\npregnant                        0\nthyroid_surgery                 0\nI131_treatment                  0\nquery_hypothyroid               0\nquery_hyperthyroid              0\nlithium                         0\ngoitre                          0\ntumor                           0\nhypopituitary                   0\npsych                           0\nTSH_measured                    0\nTSH                           369\nT3_measured                     0\nT3                            769\nTT4_measured                    0\nTT4                           231\nT4U_measured                    0\nT4U                           387\nFTI_measured                    0\nFTI                           385\nTBG_measured                    0\nTBG                          3772\nreferral_source                 0\ndtype: int64"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "data": {
      "text/plain": "age                          0.000265\nsex                          0.039767\non_thyroxine                 0.000000\nquery_on_thyroxine           0.000000\non_antithyroid_medication    0.000000\nsick                         0.000000\npregnant                     0.000000\nthyroid_surgery              0.000000\nI131_treatment               0.000000\nquery_hypothyroid            0.000000\nquery_hyperthyroid           0.000000\nlithium                      0.000000\ngoitre                       0.000000\ntumor                        0.000000\nhypopituitary                0.000000\npsych                        0.000000\nTSH_measured                 0.000000\nTSH                          0.097826\nT3_measured                  0.000000\nT3                           0.203871\nTT4_measured                 0.000000\nTT4                          0.061241\nT4U_measured                 0.000000\nT4U                          0.102598\nFTI_measured                 0.000000\nFTI                          0.102068\nTBG_measured                 0.000000\nTBG                          1.000000\nreferral_source              0.000000\ndtype: float64"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " TBG    ,   .   TSH, T3,T4U  FTI         10  ."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3772 entries, 0 to 3771\n",
      "Data columns (total 29 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   age                        3771 non-null   float64\n",
      " 1   sex                        3622 non-null   object \n",
      " 2   on_thyroxine               3772 non-null   object \n",
      " 3   query_on_thyroxine         3772 non-null   object \n",
      " 4   on_antithyroid_medication  3772 non-null   object \n",
      " 5   sick                       3772 non-null   object \n",
      " 6   pregnant                   3772 non-null   object \n",
      " 7   thyroid_surgery            3772 non-null   object \n",
      " 8   I131_treatment             3772 non-null   object \n",
      " 9   query_hypothyroid          3772 non-null   object \n",
      " 10  query_hyperthyroid         3772 non-null   object \n",
      " 11  lithium                    3772 non-null   object \n",
      " 12  goitre                     3772 non-null   object \n",
      " 13  tumor                      3772 non-null   object \n",
      " 14  hypopituitary              3772 non-null   object \n",
      " 15  psych                      3772 non-null   object \n",
      " 16  TSH_measured               3772 non-null   object \n",
      " 17  TSH                        3403 non-null   float64\n",
      " 18  T3_measured                3772 non-null   object \n",
      " 19  T3                         3003 non-null   float64\n",
      " 20  TT4_measured               3772 non-null   object \n",
      " 21  TT4                        3541 non-null   float64\n",
      " 22  T4U_measured               3772 non-null   object \n",
      " 23  T4U                        3385 non-null   float64\n",
      " 24  FTI_measured               3772 non-null   object \n",
      " 25  FTI                        3387 non-null   float64\n",
      " 26  TBG_measured               3772 non-null   object \n",
      " 27  TBG                        0 non-null      float64\n",
      " 28  referral_source            3772 non-null   object \n",
      "dtypes: float64(7), object(22)\n",
      "memory usage: 854.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "age                             1\nsex                           150\non_thyroxine                    0\nquery_on_thyroxine              0\non_antithyroid_medication       0\nsick                            0\npregnant                        0\nthyroid_surgery                 0\nI131_treatment                  0\nquery_hypothyroid               0\nquery_hyperthyroid              0\nlithium                         0\ngoitre                          0\ntumor                           0\nhypopituitary                   0\npsych                           0\nTSH_measured                    0\nTSH                           369\nT3_measured                     0\nT3                            769\nTT4_measured                    0\nTT4                           231\nT4U_measured                    0\nT4U                           387\nFTI_measured                    0\nFTI                           385\nTBG_measured                    0\nTBG                          3772\nreferral_source                 0\ndtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "age                            1\nsex                          150\non_thyroxine                   0\nquery_on_thyroxine             0\non_antithyroid_medication      0\nsick                           0\npregnant                       0\nthyroid_surgery                0\nI131_treatment                 0\nquery_hypothyroid              0\nquery_hyperthyroid             0\nlithium                        0\ngoitre                         0\ntumor                          0\nhypopituitary                  0\npsych                          0\nTSH_measured                   0\nT3_measured                    0\nTT4_measured                   0\nTT4                          231\nT4U_measured                   0\nFTI_measured                   0\nTBG_measured                   0\nreferral_source                0\ndtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3772 entries, 0 to 3771\n",
      "Data columns (total 24 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   age                        3771 non-null   float64\n",
      " 1   sex                        3622 non-null   object \n",
      " 2   on_thyroxine               3772 non-null   object \n",
      " 3   query_on_thyroxine         3772 non-null   object \n",
      " 4   on_antithyroid_medication  3772 non-null   object \n",
      " 5   sick                       3772 non-null   object \n",
      " 6   pregnant                   3772 non-null   object \n",
      " 7   thyroid_surgery            3772 non-null   object \n",
      " 8   I131_treatment             3772 non-null   object \n",
      " 9   query_hypothyroid          3772 non-null   object \n",
      " 10  query_hyperthyroid         3772 non-null   object \n",
      " 11  lithium                    3772 non-null   object \n",
      " 12  goitre                     3772 non-null   object \n",
      " 13  tumor                      3772 non-null   object \n",
      " 14  hypopituitary              3772 non-null   object \n",
      " 15  psych                      3772 non-null   object \n",
      " 16  TSH_measured               3772 non-null   object \n",
      " 17  T3_measured                3772 non-null   object \n",
      " 18  TT4_measured               3772 non-null   object \n",
      " 19  TT4                        3541 non-null   float64\n",
      " 20  T4U_measured               3772 non-null   object \n",
      " 21  FTI_measured               3772 non-null   object \n",
      " 22  TBG_measured               3772 non-null   object \n",
      " 23  referral_source            3772 non-null   object \n",
      "dtypes: float64(2), object(22)\n",
      "memory usage: 707.4+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()\n",
    "display(X.isnull().sum())\n",
    "\n",
    "X =X.drop('TBG',axis = 1)\n",
    "X =X.drop('TSH',axis = 1)\n",
    "X =X.drop('T3',axis = 1)\n",
    "X =X.drop('T4U',axis = 1)\n",
    "X =X.drop('FTI',axis = 1)\n",
    "display(X.isnull().sum())\n",
    "X.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train,features_test,target_train,target_test = train_test_split(X,y,test_size = 0.25,random_state = 12345)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "data": {
      "text/plain": "     0           1    2    3    4    5    6    7    8    9   ...   38   39  \\\n0  18.0  107.826868  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  ...  1.0  0.0   \n1  70.0  141.000000  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  ...  0.0  1.0   \n2  25.0  183.000000  1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  ...  0.0  1.0   \n3  71.0  123.000000  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  ...  0.0  1.0   \n4  26.0  113.000000  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  ...  0.0  1.0   \n\n    40   41   42   43   44   45   46   47  \n0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n1  0.0  1.0  1.0  0.0  0.0  0.0  1.0  0.0  \n2  0.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  \n3  0.0  1.0  1.0  0.0  0.0  0.0  1.0  0.0  \n4  0.0  1.0  1.0  0.0  1.0  0.0  0.0  0.0  \n\n[5 rows x 48 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>38</th>\n      <th>39</th>\n      <th>40</th>\n      <th>41</th>\n      <th>42</th>\n      <th>43</th>\n      <th>44</th>\n      <th>45</th>\n      <th>46</th>\n      <th>47</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18.0</td>\n      <td>107.826868</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>70.0</td>\n      <td>141.000000</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>25.0</td>\n      <td>183.000000</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>71.0</td>\n      <td>123.000000</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>26.0</td>\n      <td>113.000000</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows  48 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "     0           1    2    3    4    5    6    7    8    9   ...   38   39  \\\n0  46.0  233.000000  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  ...  0.0  1.0   \n1  57.0  107.826868  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  ...  1.0  0.0   \n2  23.0  107.826868  0.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  ...  1.0  0.0   \n3  26.0  107.826868  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  ...  1.0  0.0   \n4  43.0  182.000000  1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  ...  0.0  1.0   \n\n    40   41   42   43   44   45   46   47  \n0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  \n1  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n2  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n3  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n4  0.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  \n\n[5 rows x 48 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>38</th>\n      <th>39</th>\n      <th>40</th>\n      <th>41</th>\n      <th>42</th>\n      <th>43</th>\n      <th>44</th>\n      <th>45</th>\n      <th>46</th>\n      <th>47</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>46.0</td>\n      <td>233.000000</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>57.0</td>\n      <td>107.826868</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>23.0</td>\n      <td>107.826868</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>26.0</td>\n      <td>107.826868</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>43.0</td>\n      <td>182.000000</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows  48 columns</p>\n</div>"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "ohe = OneHotEncoder()\n",
    "imp = SimpleImputer(strategy = 'mean')\n",
    "\n",
    "categorical_features = X.columns[X.dtypes == 'object']\n",
    "numerical_features = X.columns[X.dtypes != 'object']\n",
    "# YOUR CODE HERE\n",
    "# define column_transformer\n",
    "\n",
    "\n",
    "\n",
    "#column_transformer = make_column_transformer((ohe,X.drop(['Age','TT4'],axis = 1)),\n",
    "                                      #       (imp,['Age','TT4']))\n",
    "#column_transformer = ColumnTransformer([\n",
    "         #  ('imp', imp, make_column_selector(dtype_include=np.number)),\n",
    "        #    ('onehot',ohe,make_column_selector(pattern='category', dtype_include=object))])\n",
    "\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('numeric',imp,numerical_features),\n",
    "    ( 'category',make_pipeline(SimpleImputer(strategy='most_frequent'),ohe),categorical_features)])\n",
    "\n",
    "# Transform the data\n",
    "X_train = column_transformer.fit_transform(features_train)\n",
    "X_test = column_transformer.transform(features_test)\n",
    "#print(X_train)\n",
    "#print(X_test)\n",
    "#X_train\n",
    "display(pd.DataFrame(X_train).head())\n",
    "pd.DataFrame(X_test).head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 2 <a id=\"task2_2\"></a> (0.7 points)\n",
    "\n",
    "Fit and compare 5 different models (use sklearn): Gradient Boosting, Random Forest, Decision Tree, SVM, Logitics Regression\n",
    "\n",
    "* Choose one classification metric and justify your choice .\n",
    "* Compare the models using score on cross validation. Mind the class balance when choosing the cross validation. (You can read more about different CV strategies [here](https://scikit-learn.org/stable/modules/cross_validation.html#stratified-k-fold))\n",
    "* Which model has the best performance? Which models overfit or underfit?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from statistics import mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "def cross_val_fit(model,skf):\n",
    "    model.fit(X_train, target_train)\n",
    "    predicted = model.predict(X_train)\n",
    "    accscore = accuracy_score(predicted, target_train)\n",
    "    f1score = f1_score(model.predict(X_train), target_train)\n",
    "    cross_valsc = cross_val_score(model, X_train, target_train, cv=skf, scoring='f1', verbose=30)\n",
    "    mean_score = sum(cross_valsc) / cross_valsc.shape\n",
    "    print('Mean of scores', mean_score)\n",
    "    print('standart Accuracy score of scores', accscore)\n",
    "    print('standart f1 score of scores', f1score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Tree Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.157) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.195) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.188) total time=   0.0s\n",
      "Mean of scores [0.18012855]\n",
      "standart Accuracy score of scores 0.9982325910215624\n",
      "standart f1 score of scores 0.9850746268656716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# YOUR CODE HERE\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "model = DecisionTreeClassifier()\n",
    "cross_val_fit(model,skf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gradient Boosting Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.125) total time=   0.4s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.234) total time=   0.5s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.088) total time=   0.5s\n",
      "Mean of scores [0.14909262]\n",
      "standart Accuracy score of scores 0.9529869211735595\n",
      "standart f1 score of scores 0.3813953488372093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.6s finished\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# YOUR CODE HERE\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "model = GradientBoostingClassifier()\n",
    "cross_val_fit(model,skf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random State Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.262) total time=   0.5s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.161) total time=   0.5s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.104) total time=   0.4s\n",
      "Mean of scores [0.17557347]\n",
      "standart Accuracy score of scores 0.9982325910215624\n",
      "standart f1 score of scores 0.9851632047477744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.5s finished\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# YOUR CODE HERE\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "model = RandomForestClassifier()\n",
    "cross_val_fit(model,skf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.000) total time=   0.1s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.000) total time=   0.1s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.000) total time=   0.0s\n",
      "Mean of scores [0.]\n",
      "standart Accuracy score of scores 0.9399080947331212\n",
      "standart f1 score of scores 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# YOUR CODE HERE\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "model = svm.SVC()\n",
    "cross_val_fit(model,skf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.000) total time=   0.0s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.123) total time=   0.0s\n",
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.032) total time=   0.0s\n",
      "Mean of scores [0.05177833]\n",
      "standart Accuracy score of scores 0.9392011311417462\n",
      "standart f1 score of scores 0.033707865168539325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# YOUR CODE HERE\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "model = LogisticRegression()\n",
    "cross_val_fit(model,skf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "```   cross val score,     - svm,    - Dicision Tree Classifier.```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 3 <a id=\"task2_3\"></a> (0.5 points)\n",
    "\n",
    "More Gradient Boosting. You will have to implement one of the three popular boosting implementations (xgboost, lightgbm, catboost). Select hyperparameters (number of trees, learning rate, depth) on cross-validation and compare with the methods from the previous task.\n",
    "\n",
    "To get method that you have to implement, run cell below and input your name in Russian (for example, if you input , you will see that user with this name should implement xgboost)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " catboost\n"
     ]
    }
   ],
   "source": [
    "def assign_method():\n",
    "    name = input()\n",
    "    methods = ['xgboost', 'lightgbm', 'catboost']\n",
    "    idx = sum([ord(x) for x in list(name)]) % 3\n",
    "    print('', methods[idx])\n",
    "\n",
    "assign_method()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "```your comments here```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 4 <a id=\"task2_4\"></a> (0.7 points)\n",
    "\n",
    "Now let's train more fancy ensembles:\n",
    "\n",
    "* Bagging with decision trees as base estimators\n",
    "* Bagging with gradient boosting (with large amount of trees, >100) as base estimators\n",
    "* [Voting classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier)\n",
    "* [Stacking Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn.ensemble.StackingClassifier) with Logistic Regression as a final model\n",
    "* [Stacking Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn.ensemble.StackingClassifier) with Gradeint Boosting as a final model\n",
    "\n",
    "\n",
    "If not stated in the task, feel free to tune / choose hyperparameters and base models.\n",
    "\n",
    "Answer the questions:\n",
    "* Which model has the best performance?\n",
    "* Does bagging reduce overfiting of the gradient boosting with large amount of trees?\n",
    "* What is the difference between voting and staking?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "```your comments here```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 5 <a id=\"task2_5\"></a> (0.1 points)\n",
    "\n",
    "Report the test score for the best model, that you were able to train."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}